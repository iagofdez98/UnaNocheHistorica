{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SprintFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyOrny0OLrS1"
      },
      "source": [
        "# **SPRINT 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcvfd0eWvlTN"
      },
      "source": [
        "# **SISTEMA DE VALORACIÓN DE ITEMS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9yjC4IowXiA"
      },
      "source": [
        "El objetivo de este sprint es mostrar el proceso desde la elección de entre las posibles preguntas por el usuario para aproximar un personaje y su posterior procesado hasta mostrar los resultados más parecidos en el dataframe según sus respuestas al test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlroj67ATmQX"
      },
      "source": [
        "# SCRIPT PARA CUBRIR LAS PREGUNTAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50_FNzhWxSu8"
      },
      "source": [
        "Primero se ejecuta el script que permitirá al usuario responder a las preguntas del test, que disponen de palabras clave relacionadas con la descripción de cada personje para facilitar el procesado. Las respuestas se almacenaran en un txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVoJ-XiBTDrr",
        "outputId": "a6a56461-ab52-4f6c-905e-5cb6d61821c2"
      },
      "source": [
        "a\n",
        "textofinal=\"\"\n",
        "Pregunta1=[\n",
        "\"1. Cual de los siguientes temas sería el elegido para una conversación?\" ,\n",
        "\"A ->Politica\", \"Loved discussing political and philosophical ideas in symposiums, which attracted many scholars. \"\n",
        ",\"B ->Famosos\" ,\"Joined societys effort to encourage art, from music to theatrics including Paint and sculpture. \"\n",
        ",\"C ->Sexo\", \"Known for his affairs, he was involved in various scandals and orgies \"\n",
        ",\"D ->¿Hablar, yo prefiero beber\", \"Fought in several wars getting numerous condecorations. \"]\n",
        "\n",
        "Pregunta2=[\n",
        "\"2. Te ofrecen una pastilla de éxtasis en medio de la noche, que haces?\"\n",
        ",\"A ->Me la tomo\", \"He was described as reckless, and acted impulsively \"\n",
        ",\"B ->Hago como que me la tomo, pero la tiro para parecer interesante\" ,\"He was heavily influenced by the ruler of his time. \"\n",
        ",\"C ->Digo que no, y no la cojo\", \"He denied pleasure, often close to estoic practices Buddhism and fanatic religion. \"\n",
        ",\"D ->La cojo, pero se la ofrezco a mis amigos\", \"He defended the ideas of democracy, and values such as generosity and social welfare. \"\n",
        "]\n",
        "\n",
        "Pregunta3=[\n",
        "\"3. Te piden que organices la música de una fiesta, sin decirte quien irá ni que se celebra, con la condición de que la música sea de un solo género. ¿Cuál elijes?\"\n",
        ",\"A ->Reggaeton\", \"Who lived in the 20th and 21st century. \"\n",
        ",\"B ->Pop\" ,\"Who lived in the modern age. \"\n",
        ",\"C ->Rock duro\", \": In the 10th and 11th century. \"\n",
        ",\"D ->Música clásica\", \"In the 1st, 2nd and 3rd century. \"\n",
        "]\n",
        "\n",
        "\n",
        "Pregunta4=[\n",
        "\"4. ¿Cual de las siguientes noticias te haría más feliz?\"\n",
        ",\"A ->Han descubierto la cura del cáncer\", \"Researcher,  scientist and medicine. \"\n",
        ",\"B ->Se ha establecido vida en marte\" ,\"Interested in exploration and trade. \"\n",
        ",\"C ->Se ha acabado con el hambre en el mundo\", \"Engaged in activism, diplomacy and non violent protest and revolution. \"\n",
        ",\"D ->Todos los gobiernos son ideales y hay justicia en el mundo\", \"Interested in law, politics and ruling. \"\n",
        "]\n",
        "\n",
        "\n",
        "Pregunta5=[\n",
        "\"5. ¿Qué tipo de alcohol bebes de fiesta?\"\n",
        ",\"A ->Cerveza\", \"I like to party with people of Czech Republic, Austria, Namibia, Germany, Poland, Ireland, Romania, Estonia, Lithuania and Spain. \"\n",
        ",\"B ->Vodka\" ,\"I like to party with people of Russia, United States, and Ukraine. \"\n",
        ",\"C ->Tequila\" , \"I like to party with people of United States, Mexico, Cuba, Chile, Colombia, Japan and France. \"\n",
        ",\"D ->No bebo\", \"I like to party with people of Pakistan, Saudi Arabia, Morocco, Egipt, Turkey, Nicaragua, Ghana. \"\n",
        "]\n",
        "\n",
        "\n",
        "Pregunta6=[\n",
        "\"6. ¿Si fueses un superhéroe, ¿Cuál sería??\"\n",
        ",\"A ->Superman\", \"I am journalist. I have a lot of strength. I could fly. I wish I were plane pilot. I like helicopters. I do not like fame. \"\n",
        ",\"B ->Spiderman\" ,\"I hace inhuman reactions, Agility, I like spiders. I like mountaineering. I love sports. I am orphan. I hate planes. I like radioactivity.  I study on college. I am shy. \"\n",
        ",\"C ->Batman\" , \"I wish i were police or politician. I have no Powers. I have too much money. I am millonaire. I am funny. I need Friends. \"\n",
        ",\"D ->Superheroe, ¿eso se come?\", \"I love sports. I hate videogames and movies. I am an uncommon person. I am comedian. \"\n",
        "]\n",
        "\n",
        "\n",
        "Pregunta7=[\n",
        "\"7. ¿Qué persona eres en tu grupo de amigos?\"\n",
        ",\"A ->El que primero se emborracha\", \"I am an impulsive person, very sensitive and manipulative. I am shy. I like alcohol. Alcoholic. I am musician. \"\n",
        ",\"B ->El que se quiere ir pronto a casa\" ,\"I am a cold person. I am writer. I am asian. I love spend time with my family. I like philosophy. \"\n",
        ",\"C ->El último en salir de la discoteca\" , \"I like to talk with people. I am outgoing. I like to party. I do sports. I hate silence. I am DJ. I am musician. I love going to festivals like tomorrowland. \"\n",
        ",\"D ->El que sale de fiesta para ligar \", \"I have many Friends. I am outgoing. I am seductive. I divorced. I never get married. I am funny. I am football player. I am psychologist. \"\n",
        "]\n",
        "\n",
        "\n",
        "Pregunta8=[\n",
        "\"8. Que actividad prefieres en una fiesta?\"\n",
        ",\"A ->Lo mío es bailar sin parar\", \"I love to dance more than anything. I am a dancer. I am energic. \"\n",
        ",\"B ->Beber alcohol hasta que salga el sol como un vikingo\" ,\"My thing is to drink alcohol like a viking until the party is over. I am always drunk. I am alcoholic. I like to drink alcohol. \"\n",
        ",\"C ->Prefiero perderme una buena conversacion a escuchar una mala cancion\" , \"I would rather miss a good conversation than listen to a bad song,  I will take care of the music. I am a musician. I love to sing. I love the art. \"\n",
        ",\"D ->Charlar y conocer gente escuchando sus historias e intereses\", \"When I am at a party I love to listen to other people stories and interests and share mine’s. I am a big talker. I am a story teller. I am a good listener. \"\n",
        "]\n",
        "\n",
        "Pregunta0=[\n",
        "\"0. Si pudieses llevar cualquier animal a una fiesta, cual llevarias?\"\n",
        ",\"A ->Un águila real, el símbolo de EEUU\", \"Easy, a golden eagle, I could do anything with the symbol of the United States on my side! I like USA. I love americans. I like guns. \"\n",
        ",\"B ->Un gran elefante\" ,\"The elephants allowed Anibal to confront the Roman Empire on their own territory, just imagine what could happen at a party. I like big animals. I like Africa. \"\n",
        ",\"C ->Un lindo oso panda\" , \"The panda bear is the most adored animal in China, so as in the rest of Asia. I like cute animals. I like anime. I like sake. I like samurais. \"\n",
        ",\"D ->Un canguro boxeador\", \"I like boxing. I like Australia. I like crocodiles. I am a fighter. I like Oceania. I like danger.\"\n",
        "]\n",
        "\n",
        "for i in range(9):\n",
        "    actual = eval(\"Pregunta\" + str(i))\n",
        "    opcion = input(actual[0] + \"\\n\" + actual[1] + \"\\n\" + actual[3]  + \"\\n\" + actual[5] + \"\\n\" + actual[7] + \"\\n\")\n",
        "    correcto= 0;\n",
        "    while(correcto == 0):\n",
        "        if opcion == 'A' or opcion=='a':\n",
        "            textofinal = textofinal  + actual[2] + \"\\n\"\n",
        "            correcto=1\n",
        "        elif opcion == 'B' or opcion=='b':\n",
        "            textofinal = textofinal  + actual[4] + \"\\n\"\n",
        "            correcto=1\n",
        "        elif opcion == 'C' or opcion=='c':\n",
        "            textofinal = textofinal  +actual[6] + \"\\n\"\n",
        "            correcto=1\n",
        "        elif opcion == 'D' or opcion=='d':\n",
        "            textofinal = textofinal  +actual[8] + \"\\n\"\n",
        "            correcto=1\n",
        "        else:\n",
        "            opcion= input(\"\\n Las únicas opciones válidas son a, b, c y d. Prueba otra vez \\n\")\n",
        "textFile= open(\"descripcionPersona.txt\", \"w\")\n",
        "n= textFile.write(textofinal)\n",
        "textFile.close()\n",
        "print(\"Tus resultados se han almacenado en descripcionPersona.txt\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0. Si pudieses llevar cualquier animal a una fiesta, cual llevarias?\n",
            "A ->Un águila real, el símbolo de EEUU\n",
            "B ->Un gran elefante\n",
            "C ->Un lindo oso panda\n",
            "D ->Un canguro boxeador\n",
            ";\n",
            "\n",
            " Las únicas opciones válidas son a, b, c y d. Prueba otra vez \n",
            "3\n",
            "\n",
            " Las únicas opciones válidas son a, b, c y d. Prueba otra vez \n",
            "a\n",
            "1. Cual de los siguientes temas sería el elegido para una conversación?\n",
            "A ->Politica\n",
            "B ->Famosos\n",
            "C ->Sexo\n",
            "D ->¿Hablar, yo prefiero beber\n",
            "a\n",
            "2. Te ofrecen una pastilla de éxtasis en medio de la noche, que haces?\n",
            "A ->Me la tomo\n",
            "B ->Hago como que me la tomo, pero la tiro para parecer interesante\n",
            "C ->Digo que no, y no la cojo\n",
            "D ->La cojo, pero se la ofrezco a mis amigos\n",
            "a\n",
            "3. Te piden que organices la música de una fiesta, sin decirte quien irá ni que se celebra, con la condición de que la música sea de un solo género. ¿Cuál elijes?\n",
            "A ->Reggaeton\n",
            "B ->Pop\n",
            "C ->Rock duro\n",
            "D ->Música clásica\n",
            "a\n",
            "4. ¿Cual de las siguientes noticias te haría más feliz?\n",
            "A ->Han descubierto la cura del cáncer\n",
            "B ->Se ha establecido vida en marte\n",
            "C ->Se ha acabado con el hambre en el mundo\n",
            "D ->Todos los gobiernos son ideales y hay justicia en el mundo\n",
            "a\n",
            "5. ¿Qué tipo de alcohol bebes de fiesta?\n",
            "A ->Cerveza\n",
            "B ->Vodka\n",
            "C ->Tequila\n",
            "D ->No bebo\n",
            "a\n",
            "6. ¿Si fueses un superhéroe, ¿Cuál sería??\n",
            "A ->Superman\n",
            "B ->Spiderman\n",
            "C ->Batman\n",
            "D ->Superheroe, ¿eso se come?\n",
            "a\n",
            "7. ¿Qué persona eres en tu grupo de amigos?\n",
            "A ->El que primero se emborracha\n",
            "B ->El que se quiere ir pronto a casa\n",
            "C ->El último en salir de la discoteca\n",
            "D ->El que sale de fiesta para ligar \n",
            "a\n",
            "8. Que actividad prefieres en una fiesta?\n",
            "A ->Lo mío es bailar sin parar\n",
            "B ->Beber alcohol hasta que salga el sol como un vikingo\n",
            "C ->Prefiero perderme una buena conversacion a escuchar una mala cancion\n",
            "D ->Charlar y conocer gente escuchando sus historias e intereses\n",
            "a\n",
            "Tus resultados se han almacenado en descripcionPersona.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdndrMCkTvZR"
      },
      "source": [
        "# Recomendador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hrsDrEEyL6n"
      },
      "source": [
        "A continuación se añade una tupla al dataframe original mediante la creación y el adjunto de un dataset que incluye las respuestas en forma de cadena."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3HmNvY6TzD5",
        "outputId": "0cc5b774-87ad-46a5-b76b-f88da3be33da"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "searchTitle = open(\"descripcionPersona.txt\", \"r\")\n",
        "var = searchTitle.read().replace('\\n', \" \")\n",
        "searchTitle.close()\n",
        "print(var)\n",
        "\n",
        "testData = pd.DataFrame({\"name\":[\"Test\"], \"Description\":[var]})\n",
        "df1 = pd.read_csv('final_dataframe.csv', engine='python',error_bad_lines=False)\n",
        "notas = []\n",
        "x = len(df1)\n",
        "i = 0\n",
        "\n",
        "while i < x:\n",
        "  notas.append(100)\n",
        "  i=i+1\n",
        "\n",
        "df1['notas'] = notas\n",
        "\n",
        "originalData = testData.append(df1.head(10000), ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Easy, a golden eagle, I could do anything with the symbol of the United States on my side! I like USA. I love americans. I like guns.  Loved discussing political and philosophical ideas in symposiums, which attracted many scholars.  He was described as reckless, and acted impulsively  Who lived in the 20th and 21st century.  Researcher,  scientist and medicine.  I like to party with people of Czech Republic, Austria, Namibia, Germany, Poland, Ireland, Romania, Estonia, Lithuania and Spain.  I am journalist. I have a lot of strength. I could fly. I wish I were plane pilot. I like helicopters. I do not like fame.  I am an impulsive person, very sensitive and manipulative. I am shy. I like alcohol. Alcoholic. I am musician.  I love to dance more than anything. I am a dancer. I am energic.  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmy8lSxi099X"
      },
      "source": [
        "# Tokenization, stemmization y eliminación de stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNLbTD761r1X"
      },
      "source": [
        "Antes de realizar la tokenizacion de la cadena con las respuestas del usuario, hay que eliminar las palabras que no aportan información relevante, las stopwords; y reducir otras a una base para facilitar el cálculo de vectores, es decir, aplicar el proceso de stemmization. Añadiremos el resultado de estas operaciones al datatext como una nueva columna: processed_text, aplicado tanto a las respuestas del usuario como a las descripciones de los personajes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lNQFtxGDUgSn",
        "outputId": "6f06ed56-bf65-4477-b448-d5a7008cea02"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "preprocessedText = []\n",
        "originalData['Description'] = originalData['Description'].apply(str)\n",
        "\n",
        "\n",
        "for row in originalData.itertuples():\n",
        "      text = word_tokenize(row[2]) ## indice de la columna que contiene el texto\n",
        "      ## Remove stop words\n",
        "      stops = set(stopwords.words(\"english\"))\n",
        "      text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "      text = \" \".join(text)\n",
        "      preprocessedText.append(text)\n",
        "\n",
        "preprocessedData = originalData\n",
        "preprocessedData['processed_text'] = preprocessedText\n",
        "\n",
        "preprocessedData\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>Description</th>\n",
              "      <th>wd_id</th>\n",
              "      <th>wp_id</th>\n",
              "      <th>slug</th>\n",
              "      <th>occupation</th>\n",
              "      <th>prob_ratio</th>\n",
              "      <th>gender</th>\n",
              "      <th>twitter</th>\n",
              "      <th>alive</th>\n",
              "      <th>l</th>\n",
              "      <th>hpi_raw</th>\n",
              "      <th>bplace_name</th>\n",
              "      <th>bplace_lat</th>\n",
              "      <th>bplace_lon</th>\n",
              "      <th>bplace_geonameid</th>\n",
              "      <th>bplace_country</th>\n",
              "      <th>bplace_continent</th>\n",
              "      <th>birthdate</th>\n",
              "      <th>birthyear</th>\n",
              "      <th>dplace_name</th>\n",
              "      <th>dplace_lat</th>\n",
              "      <th>dplace_lon</th>\n",
              "      <th>dplace_geonameid</th>\n",
              "      <th>dplace_country</th>\n",
              "      <th>dplace_continent</th>\n",
              "      <th>deathdate</th>\n",
              "      <th>deathyear</th>\n",
              "      <th>bplace_geacron_name</th>\n",
              "      <th>dplace_geacron_name</th>\n",
              "      <th>region</th>\n",
              "      <th>is_group</th>\n",
              "      <th>l_</th>\n",
              "      <th>age</th>\n",
              "      <th>non_en_page_views</th>\n",
              "      <th>coefficient_of_variation</th>\n",
              "      <th>hpi</th>\n",
              "      <th>occupation_rank</th>\n",
              "      <th>occupation_rank_unique</th>\n",
              "      <th>birthyear_rank</th>\n",
              "      <th>birthyear_rank_unique</th>\n",
              "      <th>bplace_country_rank</th>\n",
              "      <th>bplace_country_rank_unique</th>\n",
              "      <th>bplace_name_rank</th>\n",
              "      <th>bplace_name_rank_unique</th>\n",
              "      <th>deathyear_rank</th>\n",
              "      <th>deathyear_rank_unique</th>\n",
              "      <th>dplace_country_rank</th>\n",
              "      <th>dplace_country_rank_unique</th>\n",
              "      <th>dplace_name_rank</th>\n",
              "      <th>dplace_name_rank_unique</th>\n",
              "      <th>id</th>\n",
              "      <th>notas</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test</td>\n",
              "      <td>Easy, a golden eagle, I could do anything with...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easi golden eagl I could anyth symbol unit sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Muhammad Ali</td>\n",
              "      <td>Muhammad Ali (; born Cassius Marcellus Clay Jr...</td>\n",
              "      <td>q36107</td>\n",
              "      <td>63747.0</td>\n",
              "      <td>Muhammad_Ali</td>\n",
              "      <td>BOXER</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>M</td>\n",
              "      <td>MuhammadAli</td>\n",
              "      <td>False</td>\n",
              "      <td>129.0</td>\n",
              "      <td>31.824229</td>\n",
              "      <td>Louisville, Kentucky</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>-85.766667</td>\n",
              "      <td>58592.0</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1942-01-17</td>\n",
              "      <td>1942.0</td>\n",
              "      <td>Scottsdale, Arizona</td>\n",
              "      <td>33.500000</td>\n",
              "      <td>-111.933333</td>\n",
              "      <td>106659.0</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-06-03</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>17.964396</td>\n",
              "      <td>77.0</td>\n",
              "      <td>2456683.0</td>\n",
              "      <td>3.142114</td>\n",
              "      <td>87.259273</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>63747.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>muhammad ali born cassiu marcellu clay januari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baldwin I, Latin Emperor</td>\n",
              "      <td>Baldwin I (Dutch: Boudewijn; French: Baudouin;...</td>\n",
              "      <td>q298896</td>\n",
              "      <td>144424.0</td>\n",
              "      <td>Baldwin_I,_Latin_Emperor</td>\n",
              "      <td>POLITICIAN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>36.0</td>\n",
              "      <td>25.767140</td>\n",
              "      <td>Constantinople</td>\n",
              "      <td>41.013611</td>\n",
              "      <td>28.955000</td>\n",
              "      <td>3391396.0</td>\n",
              "      <td>Turkey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1172-07-01</td>\n",
              "      <td>1172.0</td>\n",
              "      <td>Veliko Tarnovo</td>\n",
              "      <td>43.077778</td>\n",
              "      <td>25.616667</td>\n",
              "      <td>193500.0</td>\n",
              "      <td>Bulgaria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1205-07-01</td>\n",
              "      <td>1205.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>8.706810</td>\n",
              "      <td>847.0</td>\n",
              "      <td>44512.0</td>\n",
              "      <td>2.495565</td>\n",
              "      <td>67.103213</td>\n",
              "      <td>1214.0</td>\n",
              "      <td>1214.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>144424.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>baldwin I dutch boudewijn french baudouin juli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Laskarina Bouboulina</td>\n",
              "      <td>Laskarina \"Bouboulina\" Pinotsis (Greek: Λασκαρ...</td>\n",
              "      <td>q237429</td>\n",
              "      <td>934118.0</td>\n",
              "      <td>Laskarina_Bouboulina</td>\n",
              "      <td>MILITARY PERSONNEL</td>\n",
              "      <td>4.082561</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.636452</td>\n",
              "      <td>Constantinople</td>\n",
              "      <td>41.013889</td>\n",
              "      <td>28.955556</td>\n",
              "      <td>3391396.0</td>\n",
              "      <td>Turkey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1771-05-11</td>\n",
              "      <td>1771.0</td>\n",
              "      <td>Spetses</td>\n",
              "      <td>37.250000</td>\n",
              "      <td>23.133333</td>\n",
              "      <td>1057236.0</td>\n",
              "      <td>Greece</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1825-05-22</td>\n",
              "      <td>1825.0</td>\n",
              "      <td>Ottoman</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>3.531231</td>\n",
              "      <td>248.0</td>\n",
              "      <td>73381.0</td>\n",
              "      <td>2.882979</td>\n",
              "      <td>56.685282</td>\n",
              "      <td>554.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>459.0</td>\n",
              "      <td>459.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>934118.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>laskarina bouboulina pinotsi greek λασκαρίνα μ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Narses</td>\n",
              "      <td>Narses (also sometimes written Nerses; Armenia...</td>\n",
              "      <td>q294781</td>\n",
              "      <td>46732.0</td>\n",
              "      <td>Narses</td>\n",
              "      <td>MILITARY PERSONNEL</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>38.0</td>\n",
              "      <td>26.105659</td>\n",
              "      <td>Constantinople</td>\n",
              "      <td>41.013889</td>\n",
              "      <td>28.955556</td>\n",
              "      <td>3391396.0</td>\n",
              "      <td>Turkey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0478-01-01</td>\n",
              "      <td>478.0</td>\n",
              "      <td>Rome</td>\n",
              "      <td>41.883333</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>25458.0</td>\n",
              "      <td>Italy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0574-01-01</td>\n",
              "      <td>574.0</td>\n",
              "      <td>Eastern Roman Empire</td>\n",
              "      <td>Eastern Roman Empire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>10.355412</td>\n",
              "      <td>1541.0</td>\n",
              "      <td>35648.0</td>\n",
              "      <td>2.245375</td>\n",
              "      <td>68.229697</td>\n",
              "      <td>108.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>449.0</td>\n",
              "      <td>449.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>46732.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>nars also sometim written ners armenian նարսես...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Anil Kapoor</td>\n",
              "      <td>Anil Kapoor (born 24 December 1956) is an Indi...</td>\n",
              "      <td>q313956</td>\n",
              "      <td>1157583.0</td>\n",
              "      <td>Anil_Kapoor</td>\n",
              "      <td>ACTOR</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>M</td>\n",
              "      <td>AnilKapoor</td>\n",
              "      <td>True</td>\n",
              "      <td>41.0</td>\n",
              "      <td>20.083241</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>18.975000</td>\n",
              "      <td>72.825833</td>\n",
              "      <td>19189.0</td>\n",
              "      <td>India</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1956-12-24</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>India</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2.275205</td>\n",
              "      <td>63.0</td>\n",
              "      <td>134281.0</td>\n",
              "      <td>5.256015</td>\n",
              "      <td>48.189011</td>\n",
              "      <td>2545.0</td>\n",
              "      <td>2545.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1157583.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>anil kapoor born 24 decemb 1956 indian actor p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Carrie Snodgress</td>\n",
              "      <td>Caroline Louise Snodgress (October 27, 1945 – ...</td>\n",
              "      <td>q266425</td>\n",
              "      <td>217821.0</td>\n",
              "      <td>Carrie_Snodgress</td>\n",
              "      <td>ACTOR</td>\n",
              "      <td>1971.591354</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>29.0</td>\n",
              "      <td>20.324020</td>\n",
              "      <td>Barrington, Illinois</td>\n",
              "      <td>42.153611</td>\n",
              "      <td>-88.131944</td>\n",
              "      <td>6886.0</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1945-10-27</td>\n",
              "      <td>1945.0</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>34.050000</td>\n",
              "      <td>-118.250000</td>\n",
              "      <td>18110.0</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2004-04-01</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2.892455</td>\n",
              "      <td>74.0</td>\n",
              "      <td>36153.0</td>\n",
              "      <td>3.994923</td>\n",
              "      <td>48.990247</td>\n",
              "      <td>2344.0</td>\n",
              "      <td>2344.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>3878.0</td>\n",
              "      <td>3878.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2821.0</td>\n",
              "      <td>2821.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>217821.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>carolin louis snodgress octob 27 1945 april 1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Corey Hawkins</td>\n",
              "      <td>Corey Antonio Hawkins (born October 22, 1988) ...</td>\n",
              "      <td>q20740941</td>\n",
              "      <td>47107515.0</td>\n",
              "      <td>Corey_Hawkins</td>\n",
              "      <td>ACTOR</td>\n",
              "      <td>2178.559086</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.472634</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1988-10-22</td>\n",
              "      <td>1988.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2.354487</td>\n",
              "      <td>31.0</td>\n",
              "      <td>42157.0</td>\n",
              "      <td>3.430583</td>\n",
              "      <td>26.191019</td>\n",
              "      <td>8217.0</td>\n",
              "      <td>8217.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47107515.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>corey antonio hawkin born octob 22 1988 americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Mory Kanté</td>\n",
              "      <td>Mory Kanté (29 March 1950 – 22 May 2020) was a...</td>\n",
              "      <td>q551576</td>\n",
              "      <td>3377337.0</td>\n",
              "      <td>Mory_Kanté</td>\n",
              "      <td>SINGER</td>\n",
              "      <td>3.710705</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.555464</td>\n",
              "      <td>Albadaria</td>\n",
              "      <td>9.550000</td>\n",
              "      <td>-10.100000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Guinea</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1950-03-29</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>5.933699</td>\n",
              "      <td>69.0</td>\n",
              "      <td>21010.0</td>\n",
              "      <td>1.876319</td>\n",
              "      <td>49.760419</td>\n",
              "      <td>659.0</td>\n",
              "      <td>659.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3377337.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>mori kanté 29 march 1950 22 may 2020 guinean v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>Jonathan Jackson</td>\n",
              "      <td>nan</td>\n",
              "      <td>q525716</td>\n",
              "      <td>674914.0</td>\n",
              "      <td>Jonathan_Jackson_(actor)</td>\n",
              "      <td>ACTOR</td>\n",
              "      <td>3397.315436</td>\n",
              "      <td>M</td>\n",
              "      <td>JonathanJackson</td>\n",
              "      <td>True</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.605477</td>\n",
              "      <td>Orlando, Florida</td>\n",
              "      <td>28.540000</td>\n",
              "      <td>-81.380000</td>\n",
              "      <td>100582.0</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2.305060</td>\n",
              "      <td>37.0</td>\n",
              "      <td>21640.0</td>\n",
              "      <td>3.554542</td>\n",
              "      <td>26.633077</td>\n",
              "      <td>8169.0</td>\n",
              "      <td>8169.0</td>\n",
              "      <td>645.0</td>\n",
              "      <td>645.0</td>\n",
              "      <td>11066.0</td>\n",
              "      <td>11066.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>674914.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10001 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           name  ...                                     processed_text\n",
              "0                          Test  ...  easi golden eagl I could anyth symbol unit sta...\n",
              "1                  Muhammad Ali  ...  muhammad ali born cassiu marcellu clay januari...\n",
              "2      Baldwin I, Latin Emperor  ...  baldwin I dutch boudewijn french baudouin juli...\n",
              "3          Laskarina Bouboulina  ...  laskarina bouboulina pinotsi greek λασκαρίνα μ...\n",
              "4                        Narses  ...  nars also sometim written ners armenian նարսես...\n",
              "...                         ...  ...                                                ...\n",
              "9996                Anil Kapoor  ...  anil kapoor born 24 decemb 1956 indian actor p...\n",
              "9997           Carrie Snodgress  ...  carolin louis snodgress octob 27 1945 april 1 ...\n",
              "9998              Corey Hawkins  ...  corey antonio hawkin born octob 22 1988 americ...\n",
              "9999                 Mory Kanté  ...  mori kanté 29 march 1950 22 may 2020 guinean v...\n",
              "10000          Jonathan Jackson  ...                                                nan\n",
              "\n",
              "[10001 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfRoXmZp5fKP"
      },
      "source": [
        "# Representación del texto como un vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXr9fEql5xdM"
      },
      "source": [
        "El siguiente paso es transformar las descripciones de los personajes en vectores de frecuencias (Bag of words), aplicando además la ponderación TF-IDF para los valores de dichas frecuencias(cuanto más se repite una palabra en el dataset, menos información aporta).\n",
        "El paquete sklearn ofrece una clase llamada TfidfVectorizer que crea automáticamente la matriz compuesta por todos los vectores de frecuencias ponderados a partir de un array de textos (preprocessedData['processed_text'])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOmrRE-qedAp",
        "outputId": "6e0427b8-cfca-4e68-bbbe-05227c6e522a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "bagOfWordsModel = TfidfVectorizer()\n",
        "bagOfWordsModel.fit(preprocessedData['processed_text'])\n",
        "textsBoW= bagOfWordsModel.transform(preprocessedData['processed_text'])\n",
        "print(\"Finished\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb6In1oDewyE",
        "outputId": "86d75ec5-788f-4048-abc5-6f38cbde5821"
      },
      "source": [
        "textsBoW.shape\n",
        "print(textsBoW)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 48112)\t0.10687666205664036\n",
            "  (0, 47899)\t0.0980599288894688\n",
            "  (0, 46128)\t0.10109222543754376\n",
            "  (0, 45896)\t0.055086905078348555\n",
            "  (0, 42974)\t0.14230858669117777\n",
            "  (0, 42955)\t0.09967144323916714\n",
            "  (0, 42292)\t0.10687666205664036\n",
            "  (0, 41953)\t0.05326259950600141\n",
            "  (0, 41559)\t0.07898327535318063\n",
            "  (0, 40600)\t0.07460355956736989\n",
            "  (0, 40311)\t0.12201659975945786\n",
            "  (0, 39838)\t0.1378156156248405\n",
            "  (0, 39463)\t0.0891892480529608\n",
            "  (0, 39367)\t0.0812112578780291\n",
            "  (0, 38040)\t0.0971672382278925\n",
            "  (0, 37457)\t0.07934862148056254\n",
            "  (0, 37441)\t0.07558879467057102\n",
            "  (0, 37036)\t0.12201659975945786\n",
            "  (0, 35206)\t0.06146833555810875\n",
            "  (0, 35183)\t0.08834483512609925\n",
            "  (0, 34981)\t0.10983221233360185\n",
            "  (0, 34815)\t0.09688066441247953\n",
            "  (0, 34622)\t0.07727470618451446\n",
            "  (0, 34399)\t0.06501967253596423\n",
            "  (0, 34282)\t0.06852316336137057\n",
            "  :\t:\n",
            "  (9999, 28698)\t0.07205081082732871\n",
            "  (9999, 28161)\t0.07284631806536546\n",
            "  (9999, 25534)\t0.4566364700583985\n",
            "  (9999, 24998)\t0.22831823502919926\n",
            "  (9999, 24801)\t0.056936398777250784\n",
            "  (9999, 23848)\t0.22831823502919926\n",
            "  (9999, 22254)\t0.08341508035580027\n",
            "  (9999, 20796)\t0.12274963062771425\n",
            "  (9999, 20121)\t0.04135833217916524\n",
            "  (9999, 19934)\t0.2063368080872743\n",
            "  (9999, 19287)\t0.2019629910866296\n",
            "  (9999, 16525)\t0.15158342041339845\n",
            "  (9999, 8914)\t0.1084372270827791\n",
            "  (9999, 6781)\t0.07085411835227476\n",
            "  (9999, 6459)\t0.1410540822515798\n",
            "  (9999, 6269)\t0.17308019295527202\n",
            "  (9999, 3098)\t0.10671736805456375\n",
            "  (9999, 3007)\t0.22831823502919926\n",
            "  (9999, 2717)\t0.13570096287565594\n",
            "  (9999, 1294)\t0.09925677394683734\n",
            "  (9999, 1196)\t0.09719245036121214\n",
            "  (9999, 1158)\t0.10428051180694466\n",
            "  (9999, 1109)\t0.10725133934591671\n",
            "  (9999, 1068)\t0.11336858497663808\n",
            "  (10000, 31182)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctzBaCnReypW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c58437d-c0fc-4f0e-ba11-98c774566a93"
      },
      "source": [
        "bagOfWordsModel.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000',\n",
              " '007',\n",
              " '009',\n",
              " '03',\n",
              " '04',\n",
              " '05',\n",
              " '07',\n",
              " '08',\n",
              " '09',\n",
              " '10',\n",
              " '100',\n",
              " '1000',\n",
              " '10000',\n",
              " '1000i',\n",
              " '1000km',\n",
              " '1000m',\n",
              " '1001',\n",
              " '1002',\n",
              " '1003',\n",
              " '1004',\n",
              " '1005',\n",
              " '1006',\n",
              " '10060',\n",
              " '1007',\n",
              " '1008',\n",
              " '1009',\n",
              " '100km',\n",
              " '100m',\n",
              " '100th',\n",
              " '101',\n",
              " '1010',\n",
              " '1011',\n",
              " '1012',\n",
              " '1013',\n",
              " '1014',\n",
              " '1015',\n",
              " '1016',\n",
              " '1017',\n",
              " '1018',\n",
              " '1019',\n",
              " '101st',\n",
              " '102',\n",
              " '1020',\n",
              " '1021',\n",
              " '1022',\n",
              " '1024',\n",
              " '1025',\n",
              " '1026',\n",
              " '1027',\n",
              " '1028',\n",
              " '1029',\n",
              " '103',\n",
              " '1031',\n",
              " '1032',\n",
              " '1033',\n",
              " '1034',\n",
              " '1035',\n",
              " '1036',\n",
              " '1037',\n",
              " '1039',\n",
              " '104',\n",
              " '1040',\n",
              " '1041',\n",
              " '1042',\n",
              " '1043',\n",
              " '1044',\n",
              " '1046',\n",
              " '1047',\n",
              " '1048',\n",
              " '1049',\n",
              " '105',\n",
              " '1050',\n",
              " '1052',\n",
              " '1054',\n",
              " '1055',\n",
              " '1056',\n",
              " '1057',\n",
              " '1058',\n",
              " '1059',\n",
              " '106',\n",
              " '1060',\n",
              " '1063',\n",
              " '1065',\n",
              " '1066',\n",
              " '1067',\n",
              " '1068',\n",
              " '106th',\n",
              " '107',\n",
              " '1070',\n",
              " '1071',\n",
              " '1072',\n",
              " '1073',\n",
              " '1075',\n",
              " '1076',\n",
              " '1077',\n",
              " '1078',\n",
              " '1079',\n",
              " '107th',\n",
              " '108',\n",
              " '1080',\n",
              " '1081',\n",
              " '1084',\n",
              " '1085',\n",
              " '1086',\n",
              " '1087',\n",
              " '1088',\n",
              " '1089',\n",
              " '109',\n",
              " '1090',\n",
              " '1091',\n",
              " '1092',\n",
              " '1093',\n",
              " '1094',\n",
              " '1095',\n",
              " '1096',\n",
              " '1097',\n",
              " '1098',\n",
              " '1099',\n",
              " '10cc',\n",
              " '10th',\n",
              " '11',\n",
              " '110',\n",
              " '1100',\n",
              " '1101',\n",
              " '1102',\n",
              " '1103',\n",
              " '1105',\n",
              " '1106',\n",
              " '1107',\n",
              " '1108',\n",
              " '1109',\n",
              " '110th',\n",
              " '111',\n",
              " '1110',\n",
              " '1111',\n",
              " '1113',\n",
              " '1115',\n",
              " '1116',\n",
              " '1117',\n",
              " '1118',\n",
              " '1119',\n",
              " '112',\n",
              " '1120',\n",
              " '1121',\n",
              " '1122',\n",
              " '1123',\n",
              " '1124',\n",
              " '1125',\n",
              " '1127',\n",
              " '1128',\n",
              " '1129',\n",
              " '113',\n",
              " '1130',\n",
              " '1131',\n",
              " '1132',\n",
              " '1133',\n",
              " '1134',\n",
              " '1135',\n",
              " '1136',\n",
              " '1137',\n",
              " '1138',\n",
              " '1139',\n",
              " '114',\n",
              " '1140',\n",
              " '1141',\n",
              " '1143',\n",
              " '1144',\n",
              " '1145',\n",
              " '1146',\n",
              " '1147',\n",
              " '1148',\n",
              " '1149',\n",
              " '115',\n",
              " '1150',\n",
              " '1151',\n",
              " '1152',\n",
              " '1153',\n",
              " '1154',\n",
              " '1155',\n",
              " '1156',\n",
              " '1157',\n",
              " '1158',\n",
              " '1159',\n",
              " '115th',\n",
              " '116',\n",
              " '1160',\n",
              " '1161',\n",
              " '1162',\n",
              " '1163',\n",
              " '1164',\n",
              " '1165',\n",
              " '1166',\n",
              " '1167',\n",
              " '1168',\n",
              " '1169',\n",
              " '116th',\n",
              " '117',\n",
              " '1170',\n",
              " '1172',\n",
              " '1173',\n",
              " '1174',\n",
              " '1175',\n",
              " '1176',\n",
              " '1177',\n",
              " '1178',\n",
              " '1179',\n",
              " '118',\n",
              " '1180',\n",
              " '1181',\n",
              " '1182',\n",
              " '1183',\n",
              " '1184',\n",
              " '1185',\n",
              " '1186',\n",
              " '1187',\n",
              " '1189',\n",
              " '119',\n",
              " '1190',\n",
              " '1191',\n",
              " '1192',\n",
              " '1193',\n",
              " '1194',\n",
              " '1195',\n",
              " '1196',\n",
              " '1197',\n",
              " '1198',\n",
              " '1199',\n",
              " '11th',\n",
              " '11x',\n",
              " '12',\n",
              " '120',\n",
              " '1200',\n",
              " '1201',\n",
              " '1202',\n",
              " '1203',\n",
              " '1204',\n",
              " '1205',\n",
              " '1206',\n",
              " '1207',\n",
              " '1208',\n",
              " '1209',\n",
              " '121',\n",
              " '1210',\n",
              " '1211',\n",
              " '1212',\n",
              " '1213',\n",
              " '1214',\n",
              " '1215',\n",
              " '1216',\n",
              " '1217',\n",
              " '1218',\n",
              " '1219',\n",
              " '121st',\n",
              " '122',\n",
              " '1220',\n",
              " '1221',\n",
              " '1222',\n",
              " '1223',\n",
              " '1224',\n",
              " '1225',\n",
              " '1226',\n",
              " '1227',\n",
              " '1228',\n",
              " '1229',\n",
              " '123',\n",
              " '1230',\n",
              " '1231',\n",
              " '1232',\n",
              " '1233',\n",
              " '1234',\n",
              " '1235',\n",
              " '1236',\n",
              " '123647',\n",
              " '1237',\n",
              " '1238',\n",
              " '1239',\n",
              " '124',\n",
              " '1240',\n",
              " '1241',\n",
              " '1242',\n",
              " '1243',\n",
              " '1244',\n",
              " '1245',\n",
              " '1246',\n",
              " '1248',\n",
              " '1249',\n",
              " '125',\n",
              " '1250',\n",
              " '1251',\n",
              " '1252',\n",
              " '1253',\n",
              " '1254',\n",
              " '1256',\n",
              " '1257',\n",
              " '1258',\n",
              " '1259',\n",
              " '125cc',\n",
              " '125gp',\n",
              " '125k',\n",
              " '125th',\n",
              " '126',\n",
              " '1260',\n",
              " '1261',\n",
              " '1262',\n",
              " '1263',\n",
              " '1265',\n",
              " '1266',\n",
              " '1267',\n",
              " '1268',\n",
              " '1269',\n",
              " '127',\n",
              " '1270',\n",
              " '1271',\n",
              " '1272',\n",
              " '1273',\n",
              " '1274',\n",
              " '1275',\n",
              " '1276',\n",
              " '1277',\n",
              " '1278',\n",
              " '1279',\n",
              " '128',\n",
              " '1280',\n",
              " '1281',\n",
              " '1282',\n",
              " '1283',\n",
              " '1284',\n",
              " '1285',\n",
              " '1286',\n",
              " '1287',\n",
              " '1288',\n",
              " '1289',\n",
              " '129',\n",
              " '1290',\n",
              " '1291',\n",
              " '1292',\n",
              " '1293',\n",
              " '1294',\n",
              " '1295',\n",
              " '1296',\n",
              " '1297',\n",
              " '1298',\n",
              " '1299',\n",
              " '12th',\n",
              " '13',\n",
              " '130',\n",
              " '1300',\n",
              " '1301',\n",
              " '1302',\n",
              " '1303',\n",
              " '1304',\n",
              " '1305',\n",
              " '1306',\n",
              " '1307',\n",
              " '1308',\n",
              " '1309',\n",
              " '131',\n",
              " '1310',\n",
              " '1311',\n",
              " '1312',\n",
              " '1313',\n",
              " '1314',\n",
              " '1315',\n",
              " '1316',\n",
              " '1317',\n",
              " '1318',\n",
              " '1319',\n",
              " '132',\n",
              " '1320',\n",
              " '1321',\n",
              " '1322',\n",
              " '1323',\n",
              " '1324',\n",
              " '1325',\n",
              " '1326',\n",
              " '1327',\n",
              " '1328',\n",
              " '1329',\n",
              " '133',\n",
              " '1330',\n",
              " '1331',\n",
              " '1332',\n",
              " '1333',\n",
              " '1334',\n",
              " '1335',\n",
              " '1336',\n",
              " '1337',\n",
              " '1338',\n",
              " '1339',\n",
              " '134',\n",
              " '1340',\n",
              " '1341',\n",
              " '1342',\n",
              " '1344',\n",
              " '1345',\n",
              " '1346',\n",
              " '1347',\n",
              " '1348',\n",
              " '1349',\n",
              " '134th',\n",
              " '135',\n",
              " '1350',\n",
              " '1351',\n",
              " '1352',\n",
              " '1353',\n",
              " '1354',\n",
              " '1355',\n",
              " '1356',\n",
              " '1357',\n",
              " '1358',\n",
              " '1359',\n",
              " '1360',\n",
              " '1362',\n",
              " '1363',\n",
              " '1364',\n",
              " '1368',\n",
              " '1369',\n",
              " '137',\n",
              " '1370',\n",
              " '1371',\n",
              " '1372',\n",
              " '1373',\n",
              " '1375',\n",
              " '1376',\n",
              " '1377',\n",
              " '1379',\n",
              " '138',\n",
              " '1380',\n",
              " '1381',\n",
              " '1382',\n",
              " '1383',\n",
              " '1384',\n",
              " '1385',\n",
              " '1386',\n",
              " '1387',\n",
              " '1388',\n",
              " '1389',\n",
              " '138th',\n",
              " '139',\n",
              " '1390',\n",
              " '1391',\n",
              " '1392',\n",
              " '1393',\n",
              " '1394',\n",
              " '1396',\n",
              " '1397',\n",
              " '1398',\n",
              " '1399',\n",
              " '13th',\n",
              " '14',\n",
              " '140',\n",
              " '1400',\n",
              " '1401',\n",
              " '1402',\n",
              " '1403',\n",
              " '1404',\n",
              " '1405',\n",
              " '1406',\n",
              " '1407',\n",
              " '1408',\n",
              " '1409',\n",
              " '141',\n",
              " '1410',\n",
              " '1411',\n",
              " '1412',\n",
              " '1413',\n",
              " '1414',\n",
              " '1415',\n",
              " '1416',\n",
              " '1417',\n",
              " '1418',\n",
              " '1419',\n",
              " '142',\n",
              " '1420',\n",
              " '1421',\n",
              " '1422',\n",
              " '1423',\n",
              " '1424',\n",
              " '1425',\n",
              " '1427',\n",
              " '1428',\n",
              " '1429',\n",
              " '143',\n",
              " '1430',\n",
              " '1431',\n",
              " '1432',\n",
              " '1433',\n",
              " '14339',\n",
              " '1434',\n",
              " '1435',\n",
              " '1436',\n",
              " '1437',\n",
              " '1438',\n",
              " '1439',\n",
              " '144',\n",
              " '1440',\n",
              " '1441',\n",
              " '1442',\n",
              " '1443',\n",
              " '1444',\n",
              " '1445',\n",
              " '1446',\n",
              " '1447',\n",
              " '1448',\n",
              " '1449',\n",
              " '145',\n",
              " '1450',\n",
              " '1452',\n",
              " '1453',\n",
              " '1454',\n",
              " '1455',\n",
              " '1456',\n",
              " '1457',\n",
              " '1458',\n",
              " '1459',\n",
              " '146',\n",
              " '1460',\n",
              " '1461',\n",
              " '1462',\n",
              " '1463',\n",
              " '1464',\n",
              " '1465',\n",
              " '1466',\n",
              " '1467',\n",
              " '1468',\n",
              " '1469',\n",
              " '147',\n",
              " '1470',\n",
              " '1471',\n",
              " '1472',\n",
              " '1473',\n",
              " '1474',\n",
              " '1475',\n",
              " '1476',\n",
              " '1477',\n",
              " '1478',\n",
              " '1479',\n",
              " '148',\n",
              " '1480',\n",
              " '1481',\n",
              " '1482',\n",
              " '1483',\n",
              " '1484',\n",
              " '1485',\n",
              " '1486',\n",
              " '1487',\n",
              " '1488',\n",
              " '1489',\n",
              " '149',\n",
              " '1490',\n",
              " '1491',\n",
              " '1492',\n",
              " '1493',\n",
              " '1494',\n",
              " '1495',\n",
              " '1496',\n",
              " '1497',\n",
              " '1498',\n",
              " '1499',\n",
              " '149th',\n",
              " '14th',\n",
              " '15',\n",
              " '150',\n",
              " '1500',\n",
              " '15000',\n",
              " '1500m',\n",
              " '1501',\n",
              " '1502',\n",
              " '1503',\n",
              " '1504',\n",
              " '1505',\n",
              " '1506',\n",
              " '1507',\n",
              " '1508',\n",
              " '150th',\n",
              " '151',\n",
              " '1510',\n",
              " '1511',\n",
              " '1512',\n",
              " '1514',\n",
              " '1515',\n",
              " '1516',\n",
              " '1517',\n",
              " '1518',\n",
              " '1519',\n",
              " '152',\n",
              " '1520',\n",
              " '1521',\n",
              " '1522',\n",
              " '1523',\n",
              " '1524',\n",
              " '1525',\n",
              " '1526',\n",
              " '1527',\n",
              " '1528',\n",
              " '1529',\n",
              " '153',\n",
              " '1530',\n",
              " '1531',\n",
              " '1532',\n",
              " '1533',\n",
              " '1534',\n",
              " '1535',\n",
              " '1536',\n",
              " '1537',\n",
              " '1538',\n",
              " '1539',\n",
              " '153rd',\n",
              " '154',\n",
              " '1540',\n",
              " '1541',\n",
              " '1542',\n",
              " '1543',\n",
              " '1544',\n",
              " '1545',\n",
              " '1546',\n",
              " '1547',\n",
              " '1548',\n",
              " '1549',\n",
              " '155',\n",
              " '1550',\n",
              " '1551',\n",
              " '1552',\n",
              " '1553',\n",
              " '1554',\n",
              " '1555',\n",
              " '1557',\n",
              " '1558',\n",
              " '1559',\n",
              " '156',\n",
              " '1560',\n",
              " '1561',\n",
              " '1562',\n",
              " '1563',\n",
              " '1564',\n",
              " '1565',\n",
              " '1566',\n",
              " '1567',\n",
              " '1568',\n",
              " '1569',\n",
              " '157',\n",
              " '1570',\n",
              " '1571',\n",
              " '1572',\n",
              " '1573',\n",
              " '1574',\n",
              " '1575',\n",
              " '1576',\n",
              " '1577',\n",
              " '1578',\n",
              " '1579',\n",
              " '158',\n",
              " '1580',\n",
              " '1581',\n",
              " '1582',\n",
              " '1583',\n",
              " '1584',\n",
              " '1585',\n",
              " '1586',\n",
              " '1587',\n",
              " '1588',\n",
              " '1589',\n",
              " '159',\n",
              " '1590',\n",
              " '1591',\n",
              " '1592',\n",
              " '1593',\n",
              " '1595',\n",
              " '1596',\n",
              " '1597',\n",
              " '1598',\n",
              " '1599',\n",
              " '15th',\n",
              " '16',\n",
              " '160',\n",
              " '1600',\n",
              " '1601',\n",
              " '1602',\n",
              " '1603',\n",
              " '1604',\n",
              " '1605',\n",
              " '1606',\n",
              " '1607',\n",
              " '1608',\n",
              " '1609',\n",
              " '161',\n",
              " '1610',\n",
              " '1611',\n",
              " '1612',\n",
              " '1613',\n",
              " '1614',\n",
              " '1615',\n",
              " '1616',\n",
              " '1617',\n",
              " '1618',\n",
              " '1619',\n",
              " '162',\n",
              " '1620',\n",
              " '1621',\n",
              " '1622',\n",
              " '1623',\n",
              " '1624',\n",
              " '1625',\n",
              " '1626',\n",
              " '1627',\n",
              " '1628',\n",
              " '1629',\n",
              " '163',\n",
              " '1630',\n",
              " '1631',\n",
              " '1632',\n",
              " '1633',\n",
              " '1634',\n",
              " '1635',\n",
              " '1636',\n",
              " '1637',\n",
              " '1638',\n",
              " '1639',\n",
              " '164',\n",
              " '1640',\n",
              " '1641',\n",
              " '1642',\n",
              " '1643',\n",
              " '1644',\n",
              " '1645',\n",
              " '1646',\n",
              " '1647',\n",
              " '1648',\n",
              " '1649',\n",
              " '165',\n",
              " '1650',\n",
              " '1651',\n",
              " '1652',\n",
              " '1654',\n",
              " '1655',\n",
              " '1656',\n",
              " '1657',\n",
              " '1658',\n",
              " '1659',\n",
              " '16593',\n",
              " '166',\n",
              " '1660',\n",
              " '1661',\n",
              " '1662',\n",
              " '1663',\n",
              " '1664',\n",
              " '1665',\n",
              " '1666',\n",
              " '1667',\n",
              " '1668',\n",
              " '1669',\n",
              " '167',\n",
              " '1670',\n",
              " '1671',\n",
              " '1672',\n",
              " '1673',\n",
              " '1674',\n",
              " '1675',\n",
              " '1676',\n",
              " '1677',\n",
              " '1678',\n",
              " '1679',\n",
              " '168',\n",
              " '1680',\n",
              " '1681',\n",
              " '1682',\n",
              " '1683',\n",
              " '1684',\n",
              " '1685',\n",
              " '1686',\n",
              " '1687',\n",
              " '1688',\n",
              " '1689',\n",
              " '169',\n",
              " '1690',\n",
              " '1691',\n",
              " '1692',\n",
              " '1693',\n",
              " '1694',\n",
              " '1695',\n",
              " '1696',\n",
              " '1697',\n",
              " '1698',\n",
              " '1699',\n",
              " '16th',\n",
              " '17',\n",
              " '170',\n",
              " '1700',\n",
              " '1701',\n",
              " '1702',\n",
              " '1703',\n",
              " '1704',\n",
              " '1705',\n",
              " '1706',\n",
              " '1707',\n",
              " '1708',\n",
              " '1709',\n",
              " '1710',\n",
              " '1711',\n",
              " '1712',\n",
              " '1713',\n",
              " '1714',\n",
              " '1715',\n",
              " '1716',\n",
              " '1717',\n",
              " '1718',\n",
              " '1719',\n",
              " '1720',\n",
              " '1721',\n",
              " '1722',\n",
              " '1723',\n",
              " '1724',\n",
              " '1725',\n",
              " '1726',\n",
              " '17260',\n",
              " '1727',\n",
              " '1728',\n",
              " '1729',\n",
              " '173',\n",
              " '1730',\n",
              " '1731',\n",
              " '1732',\n",
              " '1733',\n",
              " '1734',\n",
              " '1735',\n",
              " '1736',\n",
              " '1737',\n",
              " '1738',\n",
              " '1739',\n",
              " '174',\n",
              " '1740',\n",
              " '1741',\n",
              " '1742',\n",
              " '1743',\n",
              " '1744',\n",
              " '1745',\n",
              " '1746',\n",
              " '1747',\n",
              " '1748',\n",
              " '1749',\n",
              " '175',\n",
              " '1750',\n",
              " '1751',\n",
              " '1752',\n",
              " '1753',\n",
              " '1754',\n",
              " '1755',\n",
              " '1756',\n",
              " '1757',\n",
              " '1758',\n",
              " '1759',\n",
              " '176',\n",
              " '1760',\n",
              " '1761',\n",
              " '1762',\n",
              " '1763',\n",
              " '1764',\n",
              " '1765',\n",
              " '1766',\n",
              " '1767',\n",
              " '1768',\n",
              " '1769',\n",
              " '177',\n",
              " '1770',\n",
              " '1771',\n",
              " '1772',\n",
              " '1773',\n",
              " '1774',\n",
              " '1775',\n",
              " '1776',\n",
              " '1777',\n",
              " '1778',\n",
              " '1779',\n",
              " '178',\n",
              " '1780',\n",
              " '1781',\n",
              " '1782',\n",
              " '1783',\n",
              " '1784',\n",
              " '1785',\n",
              " '1786',\n",
              " '1787',\n",
              " '1788',\n",
              " '1789',\n",
              " '179',\n",
              " '1790',\n",
              " '1791',\n",
              " '1792',\n",
              " '1793',\n",
              " '1794',\n",
              " '1795',\n",
              " '1796',\n",
              " '1797',\n",
              " '1798',\n",
              " '1799',\n",
              " '17th',\n",
              " '18',\n",
              " '180',\n",
              " '1800',\n",
              " '1801',\n",
              " '1802',\n",
              " '1803',\n",
              " '1804',\n",
              " '1805',\n",
              " '1806',\n",
              " '1807',\n",
              " '1808',\n",
              " '1809',\n",
              " '1810',\n",
              " '1811',\n",
              " '1812',\n",
              " '1813',\n",
              " '1814',\n",
              " '1815',\n",
              " '1816',\n",
              " '1817',\n",
              " '1818',\n",
              " '1819',\n",
              " '182',\n",
              " '1820',\n",
              " '1821',\n",
              " '1822',\n",
              " '1823',\n",
              " '1824',\n",
              " '1825',\n",
              " '1826',\n",
              " '1827',\n",
              " '1828',\n",
              " '1829',\n",
              " '183',\n",
              " '1830',\n",
              " '1831',\n",
              " '1832',\n",
              " '1833',\n",
              " '1834',\n",
              " '1835',\n",
              " '1836',\n",
              " '1837',\n",
              " '1838',\n",
              " '1839',\n",
              " '184',\n",
              " '1840',\n",
              " '1841',\n",
              " '1842',\n",
              " '1843',\n",
              " '1844',\n",
              " '18447',\n",
              " '1845',\n",
              " '1846',\n",
              " '1847',\n",
              " '1848',\n",
              " '1849',\n",
              " '185',\n",
              " '1850',\n",
              " '1851',\n",
              " '1852',\n",
              " '1853',\n",
              " '1854',\n",
              " '1855',\n",
              " '1856',\n",
              " '1857',\n",
              " '1858',\n",
              " '1859',\n",
              " '186',\n",
              " '1860',\n",
              " '1860a',\n",
              " '1861',\n",
              " '1862',\n",
              " '1863',\n",
              " '1864',\n",
              " '1865',\n",
              " '1866',\n",
              " '1867',\n",
              " '1868',\n",
              " '1869',\n",
              " '187',\n",
              " '1870',\n",
              " '1871',\n",
              " '1872',\n",
              " '1873',\n",
              " '1874',\n",
              " '1875',\n",
              " '1876',\n",
              " '1877',\n",
              " '1878',\n",
              " '1879',\n",
              " '188',\n",
              " '1880',\n",
              " '1881',\n",
              " '1882',\n",
              " '1883',\n",
              " '1884',\n",
              " '1885',\n",
              " '1886',\n",
              " '1887',\n",
              " '1888',\n",
              " '1889',\n",
              " '189',\n",
              " '1890',\n",
              " '1891',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFGHidXP9JDd"
      },
      "source": [
        "# Cálculo de distancia entre vectores de frecuencias (distancia coseno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8O7nR9m9OxQ"
      },
      "source": [
        "El objetivo final es el de calcular la distancia que existe entre vector de frecuencias del personaje y el de las respuestas del usuario.\n",
        "\n",
        "Gracias a que ahora los textos están representados mediante vectores de frecuencias (textsBoW), se pueden emplear para ello medidas de distancias standard entre vectores. En este caso se usará la distancia coseno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osnG1fE0e4oW",
        "outputId": "aab1ee24-2052-4fb9-ca19-ea1041960c80"
      },
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "distance_matrix= pairwise_distances(textsBoW,textsBoW ,metric='cosine')\n",
        "print(distance_matrix.shape)\n",
        "print(type(distance_matrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10001, 10001)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37EPzgo79a6J"
      },
      "source": [
        "# Cálculo de distancia entre vectores de frecuencias (distancia manhattan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8NDJ-Qg9k_I"
      },
      "source": [
        "En esta sección comprobamos la diferencia entre el uso de la distancia coseno usada anteriormente y la distancia manhattan en este caso. El tiempo de ejecución aumenta considerablemente respecto al caso anterior, esto se debe a que para la métrica coseno se usa la implementación scikit-learn que es más rápida y tiene soporte para matrices dispersas, la métrica manhattan, en cambio, no se implementa de esa forma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwfqC4Ny989Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5953af15-a78d-4ccc-d179-a14341836b8e"
      },
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "distance_matrix= pairwise_distances(textsBoW,textsBoW ,metric='manhattan')\n",
        "print(distance_matrix.shape)\n",
        "print(type(distance_matrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10001, 10001)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UMooAYwKSCZ"
      },
      "source": [
        "# Búsqueda de los personajes más aproximados según la respuesta del usuario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK1wxtbPKsQm"
      },
      "source": [
        "En este último paso listamos los 5 personajes del dataSet cuyos vectores de frecuencias tienen una menor distancia al vector de las respuestas del usuario; es decir, los 5 personajes con una descripción aproximada a la elegida en el test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF1CzE7kfqKo",
        "outputId": "e22b01b8-c491-4cb4-a2f1-80e045096871"
      },
      "source": [
        "distance_scores = list(enumerate(distance_matrix[0]))\n",
        "i=1\n",
        "ponderado =[]\n",
        "ponderado.append((0, 0.0))\n",
        "\n",
        "while i < len(distance_scores):\n",
        "  valorPonderado= (100*distance_scores[i][1])*0.8 + originalData.iloc[i]['notas']*0.2\n",
        "  ponderado.append((i,valorPonderado))\n",
        "  i = i+1\n",
        "  \n",
        "distance_scores=ponderado\n",
        "ponderado\n",
        "\n",
        "distance_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.0),\n",
              " (1, 1482.4299051945409),\n",
              " (2, 1005.3701339112863),\n",
              " (3, 944.7693004220782),\n",
              " (4, 957.272427052455),\n",
              " (5, 1176.393925814114),\n",
              " (6, 1249.5786207002136),\n",
              " (7, 1042.144040807043),\n",
              " (8, 981.5364910710383),\n",
              " (9, 1082.556438823629),\n",
              " (10, 1038.04870235945),\n",
              " (11, 1162.4161529824362),\n",
              " (12, 1100.1721662975867),\n",
              " (13, 1150.4702848149223),\n",
              " (14, 847.932240654269),\n",
              " (15, 843.6513133933834),\n",
              " (16, 1030.8899844459147),\n",
              " (17, 878.5933279864411),\n",
              " (18, 947.9941737011413),\n",
              " (19, 994.9754156504465),\n",
              " (20, 1143.672662471743),\n",
              " (21, 896.8565279969857),\n",
              " (22, 909.4809620133749),\n",
              " (23, 1023.7733149660406),\n",
              " (24, 1144.7668190060779),\n",
              " (25, 958.3630087897584),\n",
              " (26, 663.3365241419683),\n",
              " (27, 1173.9131341913912),\n",
              " (28, 1003.6480725982483),\n",
              " (29, 1042.144040807043),\n",
              " (30, 1049.9205603295347),\n",
              " (31, 1316.8965926880626),\n",
              " (32, 1296.502880807282),\n",
              " (33, 1509.004575507628),\n",
              " (34, 1208.655832153219),\n",
              " (35, 1051.164387360073),\n",
              " (36, 1273.2759800307201),\n",
              " (37, 663.3365241419683),\n",
              " (38, 1104.4852561224768),\n",
              " (39, 1104.804657460144),\n",
              " (40, 1504.773011705819),\n",
              " (41, 1405.347118085125),\n",
              " (42, 1342.403138103137),\n",
              " (43, 1219.758648829466),\n",
              " (44, 961.0471190206789),\n",
              " (45, 1042.6624126131728),\n",
              " (46, 810.1404206042433),\n",
              " (47, 1351.0162598156926),\n",
              " (48, 1115.1863928883902),\n",
              " (49, 663.3365241419683),\n",
              " (50, 794.6961107147017),\n",
              " (51, 1138.877821459008),\n",
              " (52, 948.2028171950968),\n",
              " (53, 1179.7469198140423),\n",
              " (54, 1228.8311739859316),\n",
              " (55, 663.3365241419683),\n",
              " (56, 1109.1321854165485),\n",
              " (57, 1196.8704222399726),\n",
              " (58, 663.3365241419683),\n",
              " (59, 966.9798406522294),\n",
              " (60, 882.8626546246398),\n",
              " (61, 831.9026305394159),\n",
              " (62, 867.8105387338436),\n",
              " (63, 1087.72785782982),\n",
              " (64, 921.0419579624231),\n",
              " (65, 1242.5031912052016),\n",
              " (66, 998.8531940034496),\n",
              " (67, 663.3365241419683),\n",
              " (68, 859.2552245570444),\n",
              " (69, 1196.4025763129744),\n",
              " (70, 1047.7940769648155),\n",
              " (71, 891.9546238900656),\n",
              " (72, 934.7484618785231),\n",
              " (73, 1150.5454635104068),\n",
              " (74, 1056.8967896060326),\n",
              " (75, 869.8665499116007),\n",
              " (76, 1013.4960663367287),\n",
              " (77, 941.2745269799573),\n",
              " (78, 1150.4805686057591),\n",
              " (79, 978.7220159934914),\n",
              " (80, 1114.1652490918527),\n",
              " (81, 1251.9258188975955),\n",
              " (82, 1001.1948735058277),\n",
              " (83, 1050.9781986443688),\n",
              " (84, 1007.6299757512493),\n",
              " (85, 999.2526561487144),\n",
              " (86, 1447.4423294182982),\n",
              " (87, 1149.4335818521204),\n",
              " (88, 940.1821281845076),\n",
              " (89, 913.7076381350631),\n",
              " (90, 983.754164373024),\n",
              " (91, 1383.3972437709008),\n",
              " (92, 1344.4736908863988),\n",
              " (93, 1002.6360526460669),\n",
              " (94, 954.2061651621676),\n",
              " (95, 848.3730498213681),\n",
              " (96, 932.0774262396013),\n",
              " (97, 1095.7539545016887),\n",
              " (98, 961.1121480458573),\n",
              " (99, 1171.9892452931322),\n",
              " (100, 979.3634053991823),\n",
              " (101, 863.1654273893455),\n",
              " (102, 1025.8655043777367),\n",
              " (103, 1013.4245198165459),\n",
              " (104, 1265.2094527482616),\n",
              " (105, 887.5730244062233),\n",
              " (106, 1006.0147991605087),\n",
              " (107, 1173.504904494149),\n",
              " (108, 1182.9955335016482),\n",
              " (109, 1225.5080448475337),\n",
              " (110, 1258.497804427951),\n",
              " (111, 1054.4220672914191),\n",
              " (112, 967.2542608859285),\n",
              " (113, 663.3365241419683),\n",
              " (114, 926.933950743553),\n",
              " (115, 1116.8471859069812),\n",
              " (116, 941.1759800281085),\n",
              " (117, 1176.2063603292145),\n",
              " (118, 1445.2597608475335),\n",
              " (119, 663.3365241419683),\n",
              " (120, 1126.240176407376),\n",
              " (121, 1328.2534283274113),\n",
              " (122, 1075.9808463514044),\n",
              " (123, 1122.4412466896097),\n",
              " (124, 663.3365241419683),\n",
              " (125, 819.1606496284942),\n",
              " (126, 1291.053804537377),\n",
              " (127, 1161.4010183162216),\n",
              " (128, 1236.3599743539892),\n",
              " (129, 906.5555285949813),\n",
              " (130, 1181.2742723668816),\n",
              " (131, 903.9632770776043),\n",
              " (132, 663.3365241419683),\n",
              " (133, 1006.7852204425726),\n",
              " (134, 1205.9242826697212),\n",
              " (135, 1011.5111801967334),\n",
              " (136, 993.1772363388744),\n",
              " (137, 1162.1156246498736),\n",
              " (138, 1241.9949495035219),\n",
              " (139, 1114.0938416071376),\n",
              " (140, 1034.0411106785818),\n",
              " (141, 1078.3210041864422),\n",
              " (142, 988.1621605467416),\n",
              " (143, 1161.5208174840825),\n",
              " (144, 663.3365241419683),\n",
              " (145, 827.5010865806792),\n",
              " (146, 1052.6721768682055),\n",
              " (147, 901.4047903120735),\n",
              " (148, 1186.9307790689486),\n",
              " (149, 998.7178169610272),\n",
              " (150, 952.7904980283246),\n",
              " (151, 1054.8850024410194),\n",
              " (152, 1193.1267887816432),\n",
              " (153, 1319.7277800431616),\n",
              " (154, 892.8244310796617),\n",
              " (155, 998.1667763032827),\n",
              " (156, 924.6970704685308),\n",
              " (157, 986.9448994644614),\n",
              " (158, 1074.1333130547232),\n",
              " (159, 1042.3647463524962),\n",
              " (160, 974.2151406105767),\n",
              " (161, 916.4934191894356),\n",
              " (162, 1071.1664129049211),\n",
              " (163, 973.7552128072226),\n",
              " (164, 1376.8515665533887),\n",
              " (165, 1196.7277999920952),\n",
              " (166, 1357.7163578906316),\n",
              " (167, 1117.9446069164885),\n",
              " (168, 1035.4406027334576),\n",
              " (169, 914.0259236049078),\n",
              " (170, 663.3365241419683),\n",
              " (171, 1090.7809774212565),\n",
              " (172, 1027.679024600172),\n",
              " (173, 663.3365241419683),\n",
              " (174, 1017.2475484676785),\n",
              " (175, 855.9590828318051),\n",
              " (176, 908.0566420166442),\n",
              " (177, 1197.7462999243692),\n",
              " (178, 663.3365241419683),\n",
              " (179, 1313.6816877522078),\n",
              " (180, 942.1636795691898),\n",
              " (181, 1089.114850308685),\n",
              " (182, 851.1201604348398),\n",
              " (183, 829.4039955693133),\n",
              " (184, 1416.1272139679286),\n",
              " (185, 929.9598712327336),\n",
              " (186, 909.2674097158732),\n",
              " (187, 1016.7391710170589),\n",
              " (188, 1013.2716236574478),\n",
              " (189, 1037.739356494689),\n",
              " (190, 1003.8757480931199),\n",
              " (191, 967.8004759044115),\n",
              " (192, 996.4981840587607),\n",
              " (193, 979.5425488300021),\n",
              " (194, 1229.6341225892954),\n",
              " (195, 1057.1528792893384),\n",
              " (196, 663.3365241419683),\n",
              " (197, 868.6200683673623),\n",
              " (198, 1096.1487043889545),\n",
              " (199, 997.1216856309316),\n",
              " (200, 846.9050038232654),\n",
              " (201, 663.3365241419683),\n",
              " (202, 1181.6178123001034),\n",
              " (203, 1056.2245829315277),\n",
              " (204, 1152.0915542138953),\n",
              " (205, 965.7319343418427),\n",
              " (206, 1180.0686528989468),\n",
              " (207, 1127.0568049052433),\n",
              " (208, 1249.1578395498732),\n",
              " (209, 1105.194363975139),\n",
              " (210, 1269.9751799641915),\n",
              " (211, 1147.9874197187444),\n",
              " (212, 985.9275408777789),\n",
              " (213, 970.0002165427455),\n",
              " (214, 1069.4857552816227),\n",
              " (215, 932.8529972580578),\n",
              " (216, 1090.07139414554),\n",
              " (217, 1085.285881180168),\n",
              " (218, 954.9083464881735),\n",
              " (219, 922.6633203835369),\n",
              " (220, 1155.3934599218944),\n",
              " (221, 663.3365241419683),\n",
              " (222, 838.3525018219887),\n",
              " (223, 1019.0241409962506),\n",
              " (224, 991.9711480585171),\n",
              " (225, 1151.9448975015462),\n",
              " (226, 1288.807519207594),\n",
              " (227, 1264.1244850219316),\n",
              " (228, 1057.6332468896048),\n",
              " (229, 1063.7674528540529),\n",
              " (230, 963.5703765207095),\n",
              " (231, 958.200776427983),\n",
              " (232, 663.3365241419683),\n",
              " (233, 1277.8113176191273),\n",
              " (234, 960.9254199429121),\n",
              " (235, 1256.8499516101883),\n",
              " (236, 1053.8881590672097),\n",
              " (237, 888.1110162475851),\n",
              " (238, 925.6495333144682),\n",
              " (239, 909.3119827420301),\n",
              " (240, 1005.324854346391),\n",
              " (241, 1054.6722615158915),\n",
              " (242, 1083.776076751942),\n",
              " (243, 917.0024882002241),\n",
              " (244, 933.960661551386),\n",
              " (245, 1092.1810298696107),\n",
              " (246, 891.763605104401),\n",
              " (247, 1177.7739766397817),\n",
              " (248, 663.3365241419683),\n",
              " (249, 1207.8850163641337),\n",
              " (250, 1412.8645720056925),\n",
              " (251, 989.8086491203691),\n",
              " (252, 1089.717896993548),\n",
              " (253, 1125.9794603767855),\n",
              " (254, 965.696273217189),\n",
              " (255, 971.784641604129),\n",
              " (256, 871.567904926958),\n",
              " (257, 884.1644348977245),\n",
              " (258, 1039.7025434899508),\n",
              " (259, 1179.1393973542015),\n",
              " (260, 988.6633057870821),\n",
              " (261, 846.6772016767645),\n",
              " (262, 948.4634754575978),\n",
              " (263, 932.6700951671387),\n",
              " (264, 1160.2782147869477),\n",
              " (265, 1349.009902184094),\n",
              " (266, 1429.7629971522456),\n",
              " (267, 993.3750321152179),\n",
              " (268, 1236.7460392005626),\n",
              " (269, 1117.7130284625252),\n",
              " (270, 1113.480669352315),\n",
              " (271, 1098.4765351738783),\n",
              " (272, 1345.4283707658947),\n",
              " (273, 1444.6671608028948),\n",
              " (274, 875.7241382018658),\n",
              " (275, 663.3365241419683),\n",
              " (276, 793.5562635384493),\n",
              " (277, 911.5608557557193),\n",
              " (278, 943.1509213800642),\n",
              " (279, 663.3365241419683),\n",
              " (280, 1244.3161733270927),\n",
              " (281, 935.4794965628253),\n",
              " (282, 934.5161563488803),\n",
              " (283, 915.1054018258912),\n",
              " (284, 849.2840705421637),\n",
              " (285, 1048.9147639161956),\n",
              " (286, 663.3365241419683),\n",
              " (287, 910.4667016302709),\n",
              " (288, 1139.4989703051833),\n",
              " (289, 864.5419085135027),\n",
              " (290, 965.8672584808954),\n",
              " (291, 1082.0784819770759),\n",
              " (292, 663.3365241419683),\n",
              " (293, 1064.2151606209834),\n",
              " (294, 663.3365241419683),\n",
              " (295, 1180.2790715875788),\n",
              " (296, 1155.4349186101924),\n",
              " (297, 1001.3769656431749),\n",
              " (298, 1059.4470927577956),\n",
              " (299, 1239.0943405705998),\n",
              " (300, 663.3365241419683),\n",
              " (301, 1039.978460566968),\n",
              " (302, 1049.1589277592163),\n",
              " (303, 1088.3534868460617),\n",
              " (304, 882.6929564841469),\n",
              " (305, 939.6951518451465),\n",
              " (306, 913.2836620224564),\n",
              " (307, 941.3162118269004),\n",
              " (308, 1094.2676710235744),\n",
              " (309, 1005.066265014263),\n",
              " (310, 1213.2473886205307),\n",
              " (311, 663.3365241419683),\n",
              " (312, 1241.1980232765634),\n",
              " (313, 825.5360851279322),\n",
              " (314, 972.7065876439322),\n",
              " (315, 894.9980461407484),\n",
              " (316, 1001.6875264724831),\n",
              " (317, 663.3365241419683),\n",
              " (318, 985.5944090708185),\n",
              " (319, 933.1734426775134),\n",
              " (320, 1261.7445734214143),\n",
              " (321, 1260.8024373822802),\n",
              " (322, 846.6061941506746),\n",
              " (323, 984.9128981477772),\n",
              " (324, 1359.1299844364985),\n",
              " (325, 1175.0151486357133),\n",
              " (326, 1010.8439498497734),\n",
              " (327, 915.3122510010617),\n",
              " (328, 1044.2046110516153),\n",
              " (329, 1360.0904733696052),\n",
              " (330, 843.3539482726412),\n",
              " (331, 962.8900309085137),\n",
              " (332, 1081.5340369087662),\n",
              " (333, 663.3365241419683),\n",
              " (334, 663.3365241419683),\n",
              " (335, 663.3365241419683),\n",
              " (336, 879.415531238005),\n",
              " (337, 1055.4820563525582),\n",
              " (338, 836.6010025660504),\n",
              " (339, 1430.7087740503775),\n",
              " (340, 905.0503923331439),\n",
              " (341, 838.015248219828),\n",
              " (342, 943.2368544914839),\n",
              " (343, 1034.0395564670782),\n",
              " (344, 1072.2329203953393),\n",
              " (345, 993.3587753286738),\n",
              " (346, 1068.4165203167358),\n",
              " (347, 1165.7772391746003),\n",
              " (348, 909.075236203138),\n",
              " (349, 1211.6261843756345),\n",
              " (350, 1139.871607802613),\n",
              " (351, 663.3365241419683),\n",
              " (352, 1578.8135718025826),\n",
              " (353, 1169.3483612774444),\n",
              " (354, 954.060881206839),\n",
              " (355, 941.6778302723014),\n",
              " (356, 888.2537791598547),\n",
              " (357, 837.3030821550417),\n",
              " (358, 850.6409023290639),\n",
              " (359, 823.332697167009),\n",
              " (360, 1102.5760005039983),\n",
              " (361, 1057.6332468896048),\n",
              " (362, 1166.004455893724),\n",
              " (363, 975.3877261023365),\n",
              " (364, 990.6525235880772),\n",
              " (365, 1224.6671546925454),\n",
              " (366, 955.2561873603341),\n",
              " (367, 663.3365241419683),\n",
              " (368, 813.9703619984202),\n",
              " (369, 987.6815514982371),\n",
              " (370, 663.3365241419683),\n",
              " (371, 1099.8302858956156),\n",
              " (372, 962.0622443476949),\n",
              " (373, 1002.7141075053311),\n",
              " (374, 1081.210195677728),\n",
              " (375, 1354.8439354477468),\n",
              " (376, 933.4160892886221),\n",
              " (377, 1127.431024581615),\n",
              " (378, 964.1902197737854),\n",
              " (379, 1249.8311377643681),\n",
              " (380, 868.0533795778288),\n",
              " (381, 663.3365241419683),\n",
              " (382, 1059.057577456129),\n",
              " (383, 997.0227927966544),\n",
              " (384, 1015.5936662286693),\n",
              " (385, 1032.0057296371226),\n",
              " (386, 1075.5734127638962),\n",
              " (387, 903.255920472466),\n",
              " (388, 977.7621955550951),\n",
              " (389, 933.3783775252614),\n",
              " (390, 663.3365241419683),\n",
              " (391, 854.329197961943),\n",
              " (392, 1008.1652623697919),\n",
              " (393, 1032.9943953152551),\n",
              " (394, 957.0185820081754),\n",
              " (395, 854.8086605747854),\n",
              " (396, 922.5624338864077),\n",
              " (397, 820.7990853696222),\n",
              " (398, 663.3365241419683),\n",
              " (399, 1114.4418470912403),\n",
              " (400, 1003.2666325793227),\n",
              " (401, 928.2689012744361),\n",
              " (402, 1180.5610146731913),\n",
              " (403, 980.120409779326),\n",
              " (404, 1058.8697680453288),\n",
              " (405, 994.5773772142084),\n",
              " (406, 1087.1901708302146),\n",
              " (407, 907.4881871915632),\n",
              " (408, 946.2348720818036),\n",
              " (409, 1066.7408336318856),\n",
              " (410, 1110.6370507926429),\n",
              " (411, 932.8220526850521),\n",
              " (412, 1197.608312953709),\n",
              " (413, 800.0220422960653),\n",
              " (414, 1056.9017104263305),\n",
              " (415, 1598.6679287039701),\n",
              " (416, 1070.2917690544195),\n",
              " (417, 1317.7294693487127),\n",
              " (418, 1177.921810574231),\n",
              " (419, 1193.872117342997),\n",
              " (420, 1010.9172803927268),\n",
              " (421, 814.554566001249),\n",
              " (422, 663.3365241419683),\n",
              " (423, 991.0334807975973),\n",
              " (424, 899.7861691057415),\n",
              " (425, 911.5657168936085),\n",
              " (426, 1159.789412119182),\n",
              " (427, 1256.3590910086862),\n",
              " (428, 1012.7231022835285),\n",
              " (429, 894.9217765681877),\n",
              " (430, 1151.1404092806613),\n",
              " (431, 1092.0828204835982),\n",
              " (432, 1171.3662107209063),\n",
              " (433, 663.3365241419683),\n",
              " (434, 1352.7080001511004),\n",
              " (435, 935.5243489690238),\n",
              " (436, 1052.4388537173502),\n",
              " (437, 1073.1949131653087),\n",
              " (438, 994.7198062114605),\n",
              " (439, 1092.7051339133488),\n",
              " (440, 959.273993351774),\n",
              " (441, 837.5643280504544),\n",
              " (442, 1053.9455624634436),\n",
              " (443, 967.2553252351169),\n",
              " (444, 1279.5687197976463),\n",
              " (445, 1025.5686907225954),\n",
              " (446, 819.8729542370229),\n",
              " (447, 663.3365241419683),\n",
              " (448, 1154.3049940796816),\n",
              " (449, 1074.1948455781644),\n",
              " (450, 1076.0692648163451),\n",
              " (451, 968.859371775569),\n",
              " (452, 1047.3977486444105),\n",
              " (453, 1576.0969416973473),\n",
              " (454, 663.3365241419683),\n",
              " (455, 1003.9048910207093),\n",
              " (456, 1038.8860718647215),\n",
              " (457, 818.876023336149),\n",
              " (458, 1050.46054974911),\n",
              " (459, 1026.5793411997138),\n",
              " (460, 952.6249761909532),\n",
              " (461, 847.2623741963042),\n",
              " (462, 884.7621825203114),\n",
              " (463, 663.3365241419683),\n",
              " (464, 896.5118305880774),\n",
              " (465, 901.1115984230619),\n",
              " (466, 1195.5746808594183),\n",
              " (467, 1237.2528191788367),\n",
              " (468, 1131.5858417850777),\n",
              " (469, 902.8041544687935),\n",
              " (470, 663.3365241419683),\n",
              " (471, 946.586526502048),\n",
              " (472, 1217.9859975892632),\n",
              " (473, 663.3365241419683),\n",
              " (474, 1057.8605923708437),\n",
              " (475, 1016.2462830177403),\n",
              " (476, 944.0553761078141),\n",
              " (477, 1051.038571514157),\n",
              " (478, 1091.582859298979),\n",
              " (479, 907.5023395573644),\n",
              " (480, 1142.980013678493),\n",
              " (481, 897.3188140371203),\n",
              " (482, 1194.6187457577464),\n",
              " (483, 1207.9312375514892),\n",
              " (484, 1205.9306134445967),\n",
              " (485, 990.3876128353904),\n",
              " (486, 1150.6062730383549),\n",
              " (487, 1072.9860950350037),\n",
              " (488, 923.0696073155568),\n",
              " (489, 879.0621423005578),\n",
              " (490, 964.5794368739489),\n",
              " (491, 993.3353908578515),\n",
              " (492, 663.3365241419683),\n",
              " (493, 1063.0199263308639),\n",
              " (494, 1251.4862527310383),\n",
              " (495, 663.3365241419683),\n",
              " (496, 1009.1356349185401),\n",
              " (497, 948.9622174760804),\n",
              " (498, 1030.4408870567213),\n",
              " (499, 1069.8184688843523),\n",
              " (500, 832.5375199145033),\n",
              " (501, 1140.1156484625794),\n",
              " (502, 1018.4887923090042),\n",
              " (503, 1068.392202596736),\n",
              " (504, 1043.4196537376924),\n",
              " (505, 1090.8658870883935),\n",
              " (506, 996.2199334085674),\n",
              " (507, 921.5195163272222),\n",
              " (508, 959.9889648692948),\n",
              " (509, 837.9221848564042),\n",
              " (510, 947.2702940083127),\n",
              " (511, 663.3365241419683),\n",
              " (512, 928.0784016236644),\n",
              " (513, 902.9248113476626),\n",
              " (514, 1159.2457734641293),\n",
              " (515, 1067.3243343627769),\n",
              " (516, 1034.3312176939576),\n",
              " (517, 998.2604590731089),\n",
              " (518, 892.3311364374182),\n",
              " (519, 927.8905778315377),\n",
              " (520, 1190.0227952669045),\n",
              " (521, 905.0134358673891),\n",
              " (522, 1316.944112309574),\n",
              " (523, 1053.4340506045173),\n",
              " (524, 1250.259144674199),\n",
              " (525, 922.1016293860171),\n",
              " (526, 1209.4085697103553),\n",
              " (527, 1384.1241900090868),\n",
              " (528, 1081.6893003389494),\n",
              " (529, 1147.384603380467),\n",
              " (530, 1081.7543679602552),\n",
              " (531, 1117.5107644888858),\n",
              " (532, 925.9999593423381),\n",
              " (533, 1266.2775000296451),\n",
              " (534, 1232.9570434886025),\n",
              " (535, 942.2869929201584),\n",
              " (536, 905.5615746042372),\n",
              " (537, 1064.9268695134047),\n",
              " (538, 1001.4827201184513),\n",
              " (539, 986.1432812604166),\n",
              " (540, 840.6836384355786),\n",
              " (541, 913.1459801687454),\n",
              " (542, 1005.937738407241),\n",
              " (543, 1324.888566502195),\n",
              " (544, 899.4340347777463),\n",
              " (545, 1015.6708015175664),\n",
              " (546, 905.2875815820133),\n",
              " (547, 1029.5587986850774),\n",
              " (548, 936.1481784750827),\n",
              " (549, 1049.236066803654),\n",
              " (550, 869.6687156867737),\n",
              " (551, 983.389462528257),\n",
              " (552, 901.6929014419892),\n",
              " (553, 927.1658253236283),\n",
              " (554, 968.6946155060713),\n",
              " (555, 858.4096553890215),\n",
              " (556, 1150.34876549468),\n",
              " (557, 1126.4522109324564),\n",
              " (558, 898.2312031968706),\n",
              " (559, 1108.668316596728),\n",
              " (560, 820.1789731638901),\n",
              " (561, 922.7438171594254),\n",
              " (562, 858.7474571914205),\n",
              " (563, 1005.4169261291414),\n",
              " (564, 1272.7757023757547),\n",
              " (565, 1009.1373545254755),\n",
              " (566, 663.3365241419683),\n",
              " (567, 1116.975633397118),\n",
              " (568, 930.7255743025385),\n",
              " (569, 1110.0370638404947),\n",
              " (570, 820.4821978070452),\n",
              " (571, 919.1321951098444),\n",
              " (572, 972.433173159361),\n",
              " (573, 1072.8026083179764),\n",
              " (574, 1066.0562835849432),\n",
              " (575, 981.9734265830056),\n",
              " (576, 1009.7364680373614),\n",
              " (577, 1039.63799908833),\n",
              " (578, 1107.2343889784865),\n",
              " (579, 1072.1135167363507),\n",
              " (580, 1072.7206951830628),\n",
              " (581, 883.3153962730687),\n",
              " (582, 936.2440030892633),\n",
              " (583, 1166.7124001204324),\n",
              " (584, 820.385505692929),\n",
              " (585, 911.6069558185311),\n",
              " (586, 957.9467846720663),\n",
              " (587, 865.1440195598033),\n",
              " (588, 663.3365241419683),\n",
              " (589, 1110.8983894619694),\n",
              " (590, 1109.1975325205226),\n",
              " (591, 1327.9365794671867),\n",
              " (592, 1370.5359477060422),\n",
              " (593, 1177.9534400838054),\n",
              " (594, 927.3826660502768),\n",
              " (595, 806.2628332869665),\n",
              " (596, 1197.1981823802678),\n",
              " (597, 1073.7166393333457),\n",
              " (598, 1241.5513418463013),\n",
              " (599, 1249.4305397577634),\n",
              " (600, 1239.3859323983058),\n",
              " (601, 1183.2334750582272),\n",
              " (602, 987.1730311751179),\n",
              " (603, 1064.547589496248),\n",
              " (604, 1144.833713125874),\n",
              " (605, 1265.235482830391),\n",
              " (606, 1017.2682176804873),\n",
              " (607, 1008.6942345250402),\n",
              " (608, 1078.0614282677066),\n",
              " (609, 1211.3789355967035),\n",
              " (610, 1106.2530313606128),\n",
              " (611, 974.4017591992923),\n",
              " (612, 1245.0054221834191),\n",
              " (613, 1214.4711024818987),\n",
              " (614, 1001.1481760014218),\n",
              " (615, 990.8303544411647),\n",
              " (616, 1069.4022076706647),\n",
              " (617, 1006.4063230988709),\n",
              " (618, 1441.9220924235583),\n",
              " (619, 1012.2602212882356),\n",
              " (620, 1436.0013243084738),\n",
              " (621, 1158.2137803960402),\n",
              " (622, 1020.8361138164781),\n",
              " (623, 663.3365241419683),\n",
              " (624, 1343.0322545783802),\n",
              " (625, 1068.5335065789266),\n",
              " (626, 985.6589515022508),\n",
              " (627, 1082.469720862595),\n",
              " (628, 1161.341786686306),\n",
              " (629, 1218.4404458849058),\n",
              " (630, 1137.8260370508349),\n",
              " (631, 1012.8505344470756),\n",
              " (632, 1396.3494580698598),\n",
              " (633, 1017.6740242820802),\n",
              " (634, 1216.4930917760657),\n",
              " (635, 950.4979936034881),\n",
              " (636, 1180.9737360675786),\n",
              " (637, 1049.5814840071864),\n",
              " (638, 1397.5591527617892),\n",
              " (639, 867.6749043243095),\n",
              " (640, 939.0385746647288),\n",
              " (641, 1219.3710386024138),\n",
              " (642, 1266.8674689153029),\n",
              " (643, 1024.486720963031),\n",
              " (644, 1107.1764891055234),\n",
              " (645, 998.7431953795551),\n",
              " (646, 1222.7861214560864),\n",
              " (647, 1421.0697884589817),\n",
              " (648, 1009.8780954873727),\n",
              " (649, 857.2105400078525),\n",
              " (650, 1030.216792301177),\n",
              " (651, 1371.0154002702313),\n",
              " (652, 1349.9267674244684),\n",
              " (653, 663.3365241419683),\n",
              " (654, 829.6202866052241),\n",
              " (655, 915.8607664184813),\n",
              " (656, 1045.1565883994583),\n",
              " (657, 1513.500232785817),\n",
              " (658, 1465.053753593339),\n",
              " (659, 1073.502042502837),\n",
              " (660, 891.5650124297592),\n",
              " (661, 1184.7905855845825),\n",
              " (662, 1110.124869327067),\n",
              " (663, 886.1904810554396),\n",
              " (664, 880.1811619448245),\n",
              " (665, 1178.5944641412468),\n",
              " (666, 1225.5004307868173),\n",
              " (667, 663.3365241419683),\n",
              " (668, 1306.413175372535),\n",
              " (669, 1146.2651226538678),\n",
              " (670, 979.1798865561607),\n",
              " (671, 1220.758030577241),\n",
              " (672, 663.3365241419683),\n",
              " (673, 1105.1742473926597),\n",
              " (674, 1141.76518852399),\n",
              " (675, 1197.3290352516894),\n",
              " (676, 1271.368103768742),\n",
              " (677, 1411.435446549844),\n",
              " (678, 1268.9127379548472),\n",
              " (679, 1239.8235326160222),\n",
              " (680, 663.3365241419683),\n",
              " (681, 1165.346645231121),\n",
              " (682, 1176.0359385821446),\n",
              " (683, 1232.6536040729743),\n",
              " (684, 1209.804197927301),\n",
              " (685, 896.1577146743211),\n",
              " (686, 1355.5289152844364),\n",
              " (687, 1218.3355383416624),\n",
              " (688, 1450.763461879456),\n",
              " (689, 1359.2085419558427),\n",
              " (690, 1183.9203845120446),\n",
              " (691, 1173.0875320741022),\n",
              " (692, 1127.5927976503285),\n",
              " (693, 1202.328004999477),\n",
              " (694, 1045.8752406575927),\n",
              " (695, 1346.6231058926105),\n",
              " (696, 1288.4880186188989),\n",
              " (697, 805.578898291319),\n",
              " (698, 850.039914371885),\n",
              " (699, 997.6226768154743),\n",
              " (700, 1261.9000493385047),\n",
              " (701, 1022.7313709392407),\n",
              " (702, 1270.7917579092687),\n",
              " (703, 1136.2310575825015),\n",
              " (704, 1094.3766433346307),\n",
              " (705, 1191.0394764996797),\n",
              " (706, 1135.2862076007739),\n",
              " (707, 1196.1495648569492),\n",
              " (708, 1281.97342240567),\n",
              " (709, 1153.7783730753931),\n",
              " (710, 1282.262498363994),\n",
              " (711, 1031.3751975277678),\n",
              " (712, 817.3804013117732),\n",
              " (713, 1240.3910630688217),\n",
              " (714, 1059.2485617591738),\n",
              " (715, 1120.2231145614949),\n",
              " (716, 936.9691917184346),\n",
              " (717, 1153.2186344609906),\n",
              " (718, 1437.1626532006276),\n",
              " (719, 1031.1522053897015),\n",
              " (720, 939.3214218065855),\n",
              " (721, 1230.9777505700301),\n",
              " (722, 1025.5530174727523),\n",
              " (723, 1267.660831465844),\n",
              " (724, 1363.5196681815387),\n",
              " (725, 1125.5081131700936),\n",
              " (726, 1029.7739811814708),\n",
              " (727, 1009.1609532239518),\n",
              " (728, 1022.3287725674356),\n",
              " (729, 1073.2954087030735),\n",
              " (730, 1285.4058627529432),\n",
              " (731, 1023.4285313371389),\n",
              " (732, 846.6103022809419),\n",
              " (733, 942.9133573582499),\n",
              " (734, 1068.8996293711077),\n",
              " (735, 933.4160892886221),\n",
              " (736, 1149.4996451324507),\n",
              " (737, 1017.9308634385712),\n",
              " (738, 960.2718642675662),\n",
              " (739, 1205.4927507356726),\n",
              " (740, 1172.9155733447978),\n",
              " (741, 663.3365241419683),\n",
              " (742, 1268.3688913985782),\n",
              " (743, 1105.6087924438534),\n",
              " (744, 1526.1354621475746),\n",
              " (745, 1277.429197267176),\n",
              " (746, 1155.0546175468958),\n",
              " (747, 1292.2182022299953),\n",
              " (748, 939.6619834338392),\n",
              " (749, 884.8320495441917),\n",
              " (750, 930.6775802739184),\n",
              " (751, 924.6018017353049),\n",
              " (752, 1148.8077810425805),\n",
              " (753, 1001.8616350593562),\n",
              " (754, 951.1318970036746),\n",
              " (755, 1082.1111414177212),\n",
              " (756, 963.6370201502814),\n",
              " (757, 1070.2512754151157),\n",
              " (758, 1226.0529303382143),\n",
              " (759, 1034.8936384040437),\n",
              " (760, 1049.5801908010671),\n",
              " (761, 1109.5053499087894),\n",
              " (762, 911.4415228023408),\n",
              " (763, 928.1467172109863),\n",
              " (764, 1078.9996364965311),\n",
              " (765, 1035.3571451465925),\n",
              " (766, 1076.9964101868982),\n",
              " (767, 879.2483721060025),\n",
              " (768, 1092.817448063324),\n",
              " (769, 1174.6743127683455),\n",
              " (770, 998.4715457488921),\n",
              " (771, 828.9102629186367),\n",
              " (772, 1046.7573470514972),\n",
              " (773, 961.2657683189051),\n",
              " (774, 1138.8327255582374),\n",
              " (775, 960.4173634705639),\n",
              " (776, 903.8319133685151),\n",
              " (777, 1137.8209077987767),\n",
              " (778, 912.3555565543604),\n",
              " (779, 1049.3016407184425),\n",
              " (780, 893.8816388866946),\n",
              " (781, 1000.8750492159721),\n",
              " (782, 1117.2189537801369),\n",
              " (783, 1001.7146205717817),\n",
              " (784, 975.0228243781314),\n",
              " (785, 908.3021992560906),\n",
              " (786, 945.7134465509921),\n",
              " (787, 1162.7583486820113),\n",
              " (788, 964.1325890403377),\n",
              " (789, 1067.2442403307011),\n",
              " (790, 1059.8991554903507),\n",
              " (791, 1060.6118165007897),\n",
              " (792, 995.1735921062933),\n",
              " (793, 901.8666081373622),\n",
              " (794, 927.0138794927898),\n",
              " (795, 944.1853942965623),\n",
              " (796, 1197.7810882700462),\n",
              " (797, 920.7112283054862),\n",
              " (798, 831.6563284519746),\n",
              " (799, 663.3365241419683),\n",
              " (800, 1016.7738058279164),\n",
              " (801, 1094.318798393742),\n",
              " (802, 1143.3377739968107),\n",
              " (803, 1034.8318248243495),\n",
              " (804, 1034.6432655818967),\n",
              " (805, 1157.1384532619447),\n",
              " (806, 877.5601580969692),\n",
              " (807, 1035.2798484321352),\n",
              " (808, 933.9938120789814),\n",
              " (809, 982.8024151624574),\n",
              " (810, 829.2209205489071),\n",
              " (811, 888.2914173125919),\n",
              " (812, 663.3365241419683),\n",
              " (813, 663.3365241419683),\n",
              " (814, 975.059274179971),\n",
              " (815, 1016.3126102523265),\n",
              " (816, 848.5334135091828),\n",
              " (817, 958.7371848416544),\n",
              " (818, 812.0233751699479),\n",
              " (819, 1080.160169182626),\n",
              " (820, 936.2759677047742),\n",
              " (821, 995.8028302955295),\n",
              " (822, 934.3523084408425),\n",
              " (823, 663.3365241419683),\n",
              " (824, 1166.6007205443277),\n",
              " (825, 1220.298677567317),\n",
              " (826, 1009.8654412772954),\n",
              " (827, 1179.3736358677982),\n",
              " (828, 1201.974841933563),\n",
              " (829, 954.058916134953),\n",
              " (830, 1010.9171127519147),\n",
              " (831, 1203.3071534365254),\n",
              " (832, 1237.8462966165287),\n",
              " (833, 1069.4582420237814),\n",
              " (834, 1146.3132193982124),\n",
              " (835, 1254.1819651595035),\n",
              " (836, 1198.5665630189237),\n",
              " (837, 1209.9818798234155),\n",
              " (838, 970.1175680035449),\n",
              " (839, 1219.00678091168),\n",
              " (840, 1038.368126745594),\n",
              " (841, 1085.5388514637602),\n",
              " (842, 1023.9382023071614),\n",
              " (843, 1087.3358854690878),\n",
              " (844, 663.3365241419683),\n",
              " (845, 1136.457019722245),\n",
              " (846, 1056.4501990430324),\n",
              " (847, 1206.0135460747265),\n",
              " (848, 1303.244898128285),\n",
              " (849, 663.3365241419683),\n",
              " (850, 1083.338789311916),\n",
              " (851, 1045.2475729995385),\n",
              " (852, 1090.681430010146),\n",
              " (853, 1098.6506901012483),\n",
              " (854, 965.3084025031102),\n",
              " (855, 997.7951966838978),\n",
              " (856, 1037.4409601797215),\n",
              " (857, 971.9598774212062),\n",
              " (858, 986.3389047642974),\n",
              " (859, 942.7790106588506),\n",
              " (860, 1029.761973453717),\n",
              " (861, 1020.2651001463278),\n",
              " (862, 1160.1150813589556),\n",
              " (863, 897.7246926454729),\n",
              " (864, 934.2847957904062),\n",
              " (865, 996.4498645262225),\n",
              " (866, 1045.5445336688304),\n",
              " (867, 990.5411262782723),\n",
              " (868, 1012.2416173189972),\n",
              " (869, 1024.8217176345024),\n",
              " (870, 917.2807680989768),\n",
              " (871, 663.3365241419683),\n",
              " (872, 1220.2873646948715),\n",
              " (873, 1179.2981011797544),\n",
              " (874, 1122.1341768587283),\n",
              " (875, 1050.0275096524047),\n",
              " (876, 974.7979983392441),\n",
              " (877, 1050.4083546246432),\n",
              " (878, 932.4832578832326),\n",
              " (879, 877.5576568549412),\n",
              " (880, 852.2424346418422),\n",
              " (881, 826.894470691323),\n",
              " (882, 894.401544959837),\n",
              " (883, 815.8311722769345),\n",
              " (884, 1020.1046885713442),\n",
              " (885, 838.5754894516177),\n",
              " (886, 937.6094466641321),\n",
              " (887, 1048.092130301023),\n",
              " (888, 898.191456440995),\n",
              " (889, 983.5421442465275),\n",
              " (890, 663.3365241419683),\n",
              " (891, 663.3365241419683),\n",
              " (892, 663.3365241419683),\n",
              " (893, 1087.8919243625076),\n",
              " (894, 1168.8323805786458),\n",
              " (895, 1128.6655459485762),\n",
              " (896, 1005.5754811115218),\n",
              " (897, 980.715659113803),\n",
              " (898, 1034.0845370657971),\n",
              " (899, 663.3365241419683),\n",
              " (900, 1035.132940611366),\n",
              " (901, 663.3365241419683),\n",
              " (902, 663.3365241419683),\n",
              " (903, 833.3935458283785),\n",
              " (904, 933.7293321842394),\n",
              " (905, 1005.023972735236),\n",
              " (906, 858.8483820150913),\n",
              " (907, 663.3365241419683),\n",
              " (908, 1159.840704433436),\n",
              " (909, 1124.4492010608026),\n",
              " (910, 856.0547503894528),\n",
              " (911, 775.0516897220446),\n",
              " (912, 1154.607575517175),\n",
              " (913, 1137.184052255099),\n",
              " (914, 1159.07752256644),\n",
              " (915, 1089.441419857734),\n",
              " (916, 1074.4402615096974),\n",
              " (917, 1137.3989824555906),\n",
              " (918, 911.2242770278716),\n",
              " (919, 982.3606749154777),\n",
              " (920, 1043.3352477589901),\n",
              " (921, 772.8503812180012),\n",
              " (922, 831.7723399982768),\n",
              " (923, 1051.9090332937483),\n",
              " (924, 859.7625216442923),\n",
              " (925, 898.6749077653457),\n",
              " (926, 974.3823165345477),\n",
              " (927, 1001.1857352686441),\n",
              " (928, 905.6096441543862),\n",
              " (929, 1009.6118158913789),\n",
              " (930, 878.8006967031456),\n",
              " (931, 927.6953461893536),\n",
              " (932, 1007.709660925068),\n",
              " (933, 925.6732994242257),\n",
              " (934, 1029.7393463076928),\n",
              " (935, 1136.0529776856145),\n",
              " (936, 996.6777304996833),\n",
              " (937, 907.0743039141552),\n",
              " (938, 920.2609271331257),\n",
              " (939, 1069.5481481332665),\n",
              " (940, 880.4072430224016),\n",
              " (941, 932.0302747360607),\n",
              " (942, 1144.527708110109),\n",
              " (943, 886.4590316380536),\n",
              " (944, 889.9725911840883),\n",
              " (945, 816.1794333244374),\n",
              " (946, 880.3170580060789),\n",
              " (947, 976.722180893849),\n",
              " (948, 928.9468791520402),\n",
              " (949, 1101.907252294968),\n",
              " (950, 899.6955252630896),\n",
              " (951, 1058.280139548322),\n",
              " (952, 663.3365241419683),\n",
              " (953, 1320.853390036434),\n",
              " (954, 1149.7320570168702),\n",
              " (955, 1059.807458143552),\n",
              " (956, 875.700080741359),\n",
              " (957, 809.912196615558),\n",
              " (958, 932.6326893390706),\n",
              " (959, 1021.0892200238203),\n",
              " (960, 895.9360676786655),\n",
              " (961, 938.2514211744278),\n",
              " (962, 1051.661657376771),\n",
              " (963, 1083.5458154706425),\n",
              " (964, 1374.0086502979436),\n",
              " (965, 816.5452129178461),\n",
              " (966, 663.3365241419683),\n",
              " (967, 961.9205652821486),\n",
              " (968, 663.3365241419683),\n",
              " (969, 1035.8923510112004),\n",
              " (970, 1017.208630709636),\n",
              " (971, 741.0768388675273),\n",
              " (972, 948.9932762374727),\n",
              " (973, 811.6944446504602),\n",
              " (974, 1097.1987916515136),\n",
              " (975, 815.3826496393417),\n",
              " (976, 865.35058514193),\n",
              " (977, 1110.303597291479),\n",
              " (978, 814.5477481544294),\n",
              " (979, 663.3365241419683),\n",
              " (980, 853.6388081000891),\n",
              " (981, 1036.066239213916),\n",
              " (982, 907.9525571297416),\n",
              " (983, 1094.8427340438927),\n",
              " (984, 969.2161182912986),\n",
              " (985, 663.3365241419683),\n",
              " (986, 1109.3757264972865),\n",
              " (987, 1170.6915601949406),\n",
              " (988, 1114.8614931622617),\n",
              " (989, 1017.2298072650929),\n",
              " (990, 1015.2946445058642),\n",
              " (991, 970.3310489720893),\n",
              " (992, 853.1655849605145),\n",
              " (993, 1021.0782748149618),\n",
              " (994, 887.6397164978221),\n",
              " (995, 941.5068030269036),\n",
              " (996, 920.4117447221632),\n",
              " (997, 1136.4908117662737),\n",
              " (998, 1106.309460685791),\n",
              " (999, 976.5510082983088),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfMHba4ftgii",
        "outputId": "5cb9eb51-8455-4fb2-9720-2de49cb744d1"
      },
      "source": [
        "ordered_scores = sorted(distance_scores, key=lambda x: x[1])\n",
        "top_scores = ordered_scores[1:6]\n",
        "\n",
        "top_indexes = [i[0] for i in top_scores]\n",
        "res = preprocessedData['name'].iloc[top_indexes]\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26             Honorius\n",
              "37    Andronikos Doukas\n",
              "49               Doukas\n",
              "55               Julian\n",
              "58           Theodosius\n",
              "Name: name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNcMjispBwv2"
      },
      "source": [
        "# **SPRINT 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRDo6CSbL9Z0"
      },
      "source": [
        "En este sprint entrenaremos nuestro algoritmo de recomendación usando 2 nuevos dataframes compuestos por una serie de \"tweets\" etiquetados previamente segun sean más relevantes (-1 menos relevante y 1 más relevante). Gracias a esto podremos realizar el **análisis de sentimientos** teniendo en cuenta las valoraciones del usuario para usarlas en un sistema de puntuaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm0wvnM52jjz"
      },
      "source": [
        "# Preprocesamiento de los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoW5EhI23QRF"
      },
      "source": [
        "En este paso, como ya se hizo en el anterior sprint, leemos el dataframe (en este caso con el primer dataset de \"tweets\"),y procesamos el propio \"tweet\" alojado en la columna 'text' tokenizándolo, eliminando las stopwords y stemmizándolo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XVFHF7NHB5XR",
        "outputId": "c6c52097-5ac2-4fcb-826c-637972246af2"
      },
      "source": [
        "trainingData = pd.read_csv('semeval-2017-train.csv', delimiter='\t')\n",
        "trainingData = trainingData.head(1000) #Eliminar la funcion head() si se quiere usar todo el dataset. Para las pruebas usamos únicamente los 1000 primeros tweets\n",
        "trainingData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>One Night like In Vegas I make dat Nigga Famous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Walking through Chelsea at this time of day is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>And on the very first play of the night, Aaron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Drove the bike today, about 40 miles. Felt lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>looking at the temp outside....hpw did it get ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>Since Tottenham's game against Everton was pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>Former Cruz Azul player in the legendary 70s t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>You work? RT @SavageBeaute: Going to walk the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>@ToyceMonique I know! Im still in Alabama but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>French pressed cup of verve's Los naranjos wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                               text\n",
              "0        1    One Night like In Vegas I make dat Nigga Famous\n",
              "1        1  Walking through Chelsea at this time of day is...\n",
              "2        0  And on the very first play of the night, Aaron...\n",
              "3        0  Drove the bike today, about 40 miles. Felt lik...\n",
              "4       -1  looking at the temp outside....hpw did it get ...\n",
              "..     ...                                                ...\n",
              "995      0  Since Tottenham's game against Everton was pos...\n",
              "996      0  Former Cruz Azul player in the legendary 70s t...\n",
              "997      0  You work? RT @SavageBeaute: Going to walk the ...\n",
              "998      1  @ToyceMonique I know! Im still in Alabama but ...\n",
              "999      1  French pressed cup of verve's Los naranjos wit...\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSy0sCLi9K2q"
      },
      "source": [
        "Aquí se muestran todos los \"tweets\" en los 1000 primeros \"tweets\" por cada vallor de la etiqueta 'label'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb2zf9MHC2-H",
        "outputId": "b294cc29-b44d-4c03-8a21-65d2faba1188"
      },
      "source": [
        "trainingData['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    430\n",
              " 0    424\n",
              "-1    146\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "dCda-tBlEkxi",
        "outputId": "3106126a-9ae8-49b4-d75d-928511de734e"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "preprocessedText = []\n",
        "\n",
        "for row in trainingData.itertuples():\n",
        "    \n",
        "    \n",
        "    text = word_tokenize(row[2]) ## indice de la columna que contiene el texto\n",
        "    ## Remove stop words\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "    text = \" \".join(text)\n",
        "    \n",
        "    preprocessedText.append(text)\n",
        "\n",
        "preprocessedData = trainingData\n",
        "preprocessedData['processed_text'] = preprocessedText\n",
        "\n",
        "preprocessedData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>One Night like In Vegas I make dat Nigga Famous</td>\n",
              "      <td>one night like In vega I make dat nigga famou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Walking through Chelsea at this time of day is...</td>\n",
              "      <td>walk chelsea time day rather love love london ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>And on the very first play of the night, Aaron...</td>\n",
              "      <td>and first play night aaron rodger int udfa CB ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Drove the bike today, about 40 miles. Felt lik...</td>\n",
              "      <td>drove bike today 40 mile felt like jim carrey ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>looking at the temp outside....hpw did it get ...</td>\n",
              "      <td>look temp outsid get hotter sun goe feel like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>Since Tottenham's game against Everton was pos...</td>\n",
              "      <td>sinc tottenham game everton postpon start seas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>Former Cruz Azul player in the legendary 70s t...</td>\n",
              "      <td>former cruz azul player legendari 70 team mexi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>You work? RT @SavageBeaute: Going to walk the ...</td>\n",
              "      <td>you work RT savagebeaut go walk brooklyn bridg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>@ToyceMonique I know! Im still in Alabama but ...</td>\n",
              "      <td>toycemoniqu I know Im still alabama ill back s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>French pressed cup of verve's Los naranjos wit...</td>\n",
              "      <td>french press cup verv lo naranjo bit hank will...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                     processed_text\n",
              "0        1  ...      one night like In vega I make dat nigga famou\n",
              "1        1  ...  walk chelsea time day rather love love london ...\n",
              "2        0  ...  and first play night aaron rodger int udfa CB ...\n",
              "3        0  ...  drove bike today 40 mile felt like jim carrey ...\n",
              "4       -1  ...  look temp outsid get hotter sun goe feel like ...\n",
              "..     ...  ...                                                ...\n",
              "995      0  ...  sinc tottenham game everton postpon start seas...\n",
              "996      0  ...  former cruz azul player legendari 70 team mexi...\n",
              "997      0  ...  you work RT savagebeaut go walk brooklyn bridg...\n",
              "998      1  ...  toycemoniqu I know Im still alabama ill back s...\n",
              "999      1  ...  french press cup verv lo naranjo bit hank will...\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE9AJXrR4W5q"
      },
      "source": [
        "# Creación de la bolsa de palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ-docgj4M-C"
      },
      "source": [
        "Ahora creamos creamos los vectores de frecuencias que contienen el texto procesado correspondiente a los \"tweets\" originales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMNnqtc5EmIu",
        "outputId": "14033dab-7305-4e66-9623-fef535ec87d9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "bagOfWordsModel = TfidfVectorizer()\n",
        "bagOfWordsModel.fit(preprocessedData['processed_text'])\n",
        "textsBoW= bagOfWordsModel.transform(preprocessedData['processed_text'])\n",
        "print(\"Finished\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy2SPaF8Eo4k",
        "outputId": "f7a3bf4e-3f45-46f7-c979-59665cf680c9"
      },
      "source": [
        "textsBoW.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 3582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LK-JyZ545Gm"
      },
      "source": [
        "# Entrenamiento de un algoritmo de clasificación (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux7pF6Fk51HK"
      },
      "source": [
        "Para entrenar el algoritmo debemos separar la parte correspondiente a la bagOfWords (los datos de prueba) y los datos de entrenamiento. A continuación se entrena el algoritmo utilizando un fit(datos de prueba, datos de entrenamiento)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTVMB9BbEqmS",
        "outputId": "dbb42999-56f7-4135-fb6b-b187bcb51761"
      },
      "source": [
        "from sklearn import svm\n",
        "svc = svm.SVC(kernel='linear') #Modelo de clasificación\n",
        "\n",
        "X_train = textsBoW #Documentos\n",
        "Y_train = trainingData['label'] #Etiquetas de los documentos \n",
        "svc.fit(X_train, Y_train) #Entrenamiento\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eUXX1Bo7KY9"
      },
      "source": [
        "# Carga y preprocesado de documentos de test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpacATGN7gz1"
      },
      "source": [
        "Leemos y preprocesamos los datos del segundo dataframe de \"tweets\", escogiendo los 10000 primeros para conseguir más datos y con ello más precisión en las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "GOCclyv_EtpQ",
        "outputId": "6ef87bf8-509c-49c5-d6a6-e872fd9391a1"
      },
      "source": [
        "testData = pd.read_csv('semeval-2017-test.csv', delimiter='\t')\n",
        "testData = testData.head(10000)\n",
        "testData\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Trump is building a wall on the Mexican border...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>@lasinferencias &amp; the WALL Trump wants to buil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>President Elect? More like President Erect! A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok, I know a lot of you think a wall on the Me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The Great Mexican Wall Deception: Trump's Amer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>-1</td>\n",
              "      <td>@DataLogicTruth @VanJones68 where is the FBI o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>#DidYouKnow diabetes can affect the kidneys re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>@merrittk are you hoping for a Marine Le Pen win?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>#NFL 2011 Panini Gold Standard #27 Vincent Bro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>#Basketball #Buzz 2013-14 Panini Gold Standard...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "0         0  Trump is building a wall on the Mexican border...\n",
              "1        -1  @lasinferencias & the WALL Trump wants to buil...\n",
              "2        -1  President Elect? More like President Erect! A ...\n",
              "3         0  Ok, I know a lot of you think a wall on the Me...\n",
              "4         0  The Great Mexican Wall Deception: Trump's Amer...\n",
              "...     ...                                                ...\n",
              "9995     -1  @DataLogicTruth @VanJones68 where is the FBI o...\n",
              "9996      0  #DidYouKnow diabetes can affect the kidneys re...\n",
              "9997      0  @merrittk are you hoping for a Marine Le Pen win?\n",
              "9998      0  #NFL 2011 Panini Gold Standard #27 Vincent Bro...\n",
              "9999      0  #Basketball #Buzz 2013-14 Panini Gold Standard...\n",
              "\n",
              "[10000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7DVvyeFEFDZ-",
        "outputId": "021a3a1e-afbd-4eca-d670-1ce282ee1922"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "preprocessedText = []\n",
        "\n",
        "for row in testData.itertuples():\n",
        "    \n",
        "    \n",
        "    text = word_tokenize(row[2]) ## indice de la columna que contiene el texto\n",
        "    ## Remove stop words\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "    text = \" \".join(text)\n",
        "    \n",
        "    preprocessedText.append(text)\n",
        "\n",
        "preprocessedDataTest = testData\n",
        "preprocessedDataTest['processed_text'] = preprocessedText\n",
        "\n",
        "preprocessedDataTest\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Trump is building a wall on the Mexican border...</td>\n",
              "      <td>trump build wall mexican border stop herrion c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>@lasinferencias &amp; the WALL Trump wants to buil...</td>\n",
              "      <td>lasinferencia wall trump want build I research...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>President Elect? More like President Erect! A ...</td>\n",
              "      <td>presid elect more like presid erect A wall On ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok, I know a lot of you think a wall on the Me...</td>\n",
              "      <td>Ok I know lot think wall mexican border insan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The Great Mexican Wall Deception: Trump's Amer...</td>\n",
              "      <td>the great mexican wall decept trump america al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>-1</td>\n",
              "      <td>@DataLogicTruth @VanJones68 where is the FBI o...</td>\n",
              "      <td>datalogictruth vanjones68 fbi trump question p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>#DidYouKnow diabetes can affect the kidneys re...</td>\n",
              "      <td>didyouknow diabet affect kidney result kidney ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>@merrittk are you hoping for a Marine Le Pen win?</td>\n",
              "      <td>merrittk hope marin Le pen win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>#NFL 2011 Panini Gold Standard #27 Vincent Bro...</td>\n",
              "      <td>nfl 2011 panini gold standard 27 vincent brown...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>#Basketball #Buzz 2013-14 Panini Gold Standard...</td>\n",
              "      <td>basketbal buzz panini gold standard 2 dwight h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                     processed_text\n",
              "0         0  ...  trump build wall mexican border stop herrion c...\n",
              "1        -1  ...  lasinferencia wall trump want build I research...\n",
              "2        -1  ...  presid elect more like presid erect A wall On ...\n",
              "3         0  ...  Ok I know lot think wall mexican border insan ...\n",
              "4         0  ...  the great mexican wall decept trump america al...\n",
              "...     ...  ...                                                ...\n",
              "9995     -1  ...  datalogictruth vanjones68 fbi trump question p...\n",
              "9996      0  ...  didyouknow diabet affect kidney result kidney ...\n",
              "9997      0  ...                     merrittk hope marin Le pen win\n",
              "9998      0  ...  nfl 2011 panini gold standard 27 vincent brown...\n",
              "9999      0  ...  basketbal buzz panini gold standard 2 dwight h...\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9UjV3qG-lLQ"
      },
      "source": [
        "En este paso se muestra el número de \"tweets\" por cada etiqueta sobre los 10000 del segundo dataframe y se crean nuevos vectores de frecuencias utilizando la misma representación de bolsa de palabras que se usó para entrenar el algoritmo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zXKiYseDCl9",
        "outputId": "c5cf6d6c-5621-4cb4-901e-5ac66e2bb722"
      },
      "source": [
        "testData['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    4678\n",
              "-1    3218\n",
              " 1    2104\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDjAKdZbFHiU",
        "outputId": "60445e79-f375-478b-b19b-ceddce427ae3"
      },
      "source": [
        "textsBoWTest= bagOfWordsModel.transform(preprocessedDataTest['processed_text'])\n",
        "print(\"Finished\")\n",
        "textsBoWTest.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w875ojrGDh3M"
      },
      "source": [
        "# Clasificación de los documentos de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VI6PHWFFLfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2454c1c6-8d8c-4d84-e582-f3a211ed9262"
      },
      "source": [
        "X_test = textsBoWTest #Documentos\n",
        "\n",
        "predictions = svc.predict(X_test) #Se almacena en el array predictions las predicciones del clasificador\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<10000x3582 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 55819 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERjOpbieDtdN"
      },
      "source": [
        "# Evaluación de la predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMogT1FCEJM2"
      },
      "source": [
        "En el siguiente fragmento se muestran distintos valores como la precisión de las predicciones para cada una de las etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD47ZWJCFNe2",
        "outputId": "ee28fa32-4ae1-4e7b-a0a8-08d169951749"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "Y_test = testData['label'] #Etiquetas reales de los documentos\n",
        "\n",
        "print (classification_report(Y_test, predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.06      0.11      3218\n",
            "           0       0.52      0.77      0.62      4678\n",
            "           1       0.35      0.47      0.40      2104\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.50      0.43      0.38     10000\n",
            "weighted avg       0.52      0.48      0.41     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP3CQXcTGbts"
      },
      "source": [
        "# Entrenamiento y Evaluación de otro algoritmo de clasificación: k-NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnG1nOKTE7SA"
      },
      "source": [
        "En esta sección usamos el algoritmo de clasificación k-NN, que clasifica los elementos en base a la distancia de los k-vecinos más próximos. Le aportamosal algoritmo diferentes valores de k para comparar resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxq26J-DFr9O"
      },
      "source": [
        "## Clasificación con k = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmTlg07EFQOl",
        "outputId": "1a8c0004-892b-44ff-8c22-232ac04af1c4"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "\n",
        "neigh.fit(X_train, Y_train) \n",
        "predictions = neigh.predict(X_test) \n",
        "\n",
        "print (classification_report(Y_test, predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.40      0.40      3218\n",
            "           0       0.50      0.51      0.51      4678\n",
            "           1       0.31      0.27      0.29      2104\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.40      0.40      0.40     10000\n",
            "weighted avg       0.42      0.43      0.42     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeULV6wlF35P"
      },
      "source": [
        "## Clasificación con k=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSOxS0XHGGt9"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "\n",
        "neigh.fit(X_train, Y_train) \n",
        "predictions = neigh.predict(X_test) \n",
        "\n",
        "print (classification_report(Y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTFS65fIF9lQ"
      },
      "source": [
        "## Clasificación con k=5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfcTsBGMGHXC"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "\n",
        "neigh.fit(X_train, Y_train) \n",
        "predictions = neigh.predict(X_test) \n",
        "\n",
        "print (classification_report(Y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL_OSGuLHNvW"
      },
      "source": [
        "A continuación introducimos una opinión (claramente negativa) de ejemplo, y tras aplicar el procedimiento habitual (preprocesado y transformación en vector de frecuencias) y realizar una predicción obtenemos el valor esperado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPaDOekqHfLS"
      },
      "source": [
        "## Predicciones y valoraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0p8eJ5wFrrT",
        "outputId": "64d69dea-70a6-48d1-d0f6-697dc317f631"
      },
      "source": [
        "opinion = \"I hate it\"\n",
        "opinion=[opinion]\n",
        "dfOpinion = pd.DataFrame()\n",
        "dfOpinion['opinion'] = opinion\n",
        "dfOpinion\n",
        "ps = PorterStemmer()\n",
        "\n",
        "preprocessedTextOpinion = []\n",
        "\n",
        "for row in dfOpinion.itertuples():\n",
        "    \n",
        "    \n",
        "    text = word_tokenize(row[1]) ## indice de la columna que contiene el texto\n",
        "    ## Remove stop words\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "    text = \" \".join(text)\n",
        "    \n",
        "    preprocessedTextOpinion.append(text)\n",
        "\n",
        "preprocessedData = dfOpinion\n",
        "preprocessedData['processed_text'] = preprocessedTextOpinion\n",
        "\n",
        "\n",
        "textsBoWOpinion= bagOfWordsModel.transform(preprocessedData['processed_text'])\n",
        "print(\"Finished\")\n",
        "textsBoWOpinion.shape\n",
        "X_test = textsBoWOpinion #Documentos\n",
        "predictions = svc.predict(X_test) #Se almacena en el array predictions las predicciones del clasificador\n",
        "predictions[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xO0QJ2qJRHL"
      },
      "source": [
        "El siguiente paso es realizar las predicciones sobre las opiniones del usuario; para ello se le pide que las introduzca para la noche y para cada uno de los personajes que se le han recomendado en forma de caracter único (B)ien, (M)al o (I)do not know y le pedimos también una opinión general en forma de texto, que se procesará posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm3Hg3InQE5U",
        "outputId": "3830e38a-89d0-4d0b-9a91-3d5637762755"
      },
      "source": [
        "val= []\n",
        "i = 0\n",
        "\n",
        "while i <5:\n",
        "\n",
        "  inputCorrecto = False\n",
        "  while inputCorrecto == False:\n",
        "    print(\"¿Cuál es tu opinión acerca de \" + res.iloc[i] + \"? Bien(B)/Mal(M)/Idk(I)\")\n",
        "    aux = input()\n",
        "    aux.lower()\n",
        "\n",
        "    if aux == 'b' or aux== 'm' or aux == 'i':\n",
        "      val.append(aux)\n",
        "      i = i+1\n",
        "      inputCorrecto = True\n",
        "\n",
        "input2 = False \n",
        "while input2 == False:\n",
        "  print(\"¿Cuál es tu opinión acerca de la noche? Bien(B)/Mal(M)/Idk(I)\")\n",
        "  aux = input()\n",
        "  aux.lower()\n",
        "\n",
        "  if aux == 'b' or aux== 'm' or aux == 'i':\n",
        "    val.append(aux)\n",
        "    i = i+1\n",
        "    input2 = True\n",
        "  opinion=input(\"¿Podrías decirnos que te parece la noche en unas frases breves? En inglés por favor\")\n",
        "  opinion.lower()\n",
        "  dfOpinion = pd.DataFrame()\n",
        "  dfOpinion['opinion'] = opinion\n",
        "  ps = PorterStemmer()\n",
        "  preprocessedTextOpinion = []\n",
        "\n",
        "  for row in dfOpinion.itertuples(): \n",
        "    text = word_tokenize(row[1]) ## indice de la columna que contiene el texto\n",
        "    ## Remove stop wordsa\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "    text = \" \".join(text)\n",
        "  preprocessedTextOpinion.append(text)\n",
        "  preprocessedData = dfOpinion\n",
        "  preprocessedData['processed_text'] = preprocessedTextOpinion\n",
        "  textsBoWOpinion= bagOfWordsModel.transform(preprocessedData['processed_text'])\n",
        "  print(\"Finished\")\n",
        "  textsBoWOpinion.shape\n",
        "  X_test = textsBoWOpinion #Documentos\n",
        "  predictions = svc.predict(X_test) #Se almacena en el array predictions las predicciones del clasificador\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "¿Cuál es tu opinión acerca de Mike Love? Bien(B)/Mal(M)/Idk(I)\n",
            "b\n",
            "¿Cuál es tu opinión acerca de Oliver Nelson? Bien(B)/Mal(M)/Idk(I)\n",
            "b\n",
            "¿Cuál es tu opinión acerca de Silvio Rodríguez? Bien(B)/Mal(M)/Idk(I)\n",
            "m\n",
            "¿Cuál es tu opinión acerca de Meg Ryan? Bien(B)/Mal(M)/Idk(I)\n",
            "i\n",
            "¿Cuál es tu opinión acerca de Wisława Szymborska? Bien(B)/Mal(M)/Idk(I)\n",
            "b\n",
            "¿Cuál es tu opinión acerca de la noche? Bien(B)/Mal(M)/Idk(I)\n",
            "i\n",
            "¿Podrías decirnos que te parece la noche en unas frases breves? En inglés por favorI love it\n",
            "Finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b', 'b', 'm', 'i', 'b', 'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKv2pGCvLxIQ"
      },
      "source": [
        "Por último le asigna un valor a cada opinión (B: 1, M:-1, I: 0) y se añade al ya existente en la columna notas para cada uno de los personajes recomendados; en el caso de la opinión general de la noche se añade ese valor a todos ellos. De esta forma conseguimos hacer más o menos populares a los personajes en función de estas valoraciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmHQDXkHUGg7",
        "outputId": "ae6bb2de-efbd-40b1-b000-a2ed02442c3d"
      },
      "source": [
        "j = 0\n",
        "\n",
        "while j <5:  \n",
        "  col = originalData.loc[:, 'name'] == res.iloc[j]\n",
        "  nota = originalData[col]['notas']\n",
        "\n",
        "  if val[j] == 'm':\n",
        "    nota = nota -1\n",
        "  elif val[j] == 'b':\n",
        "    nota = nota +1.5\n",
        "  elif val[j] =='i':\n",
        "    nota = nota -0.5\n",
        "  nota = nota + predictions[0]\n",
        "  print(predictions[0])\n",
        "  originalData.at[col,'notas'] = nota\n",
        "  j = j+1\n",
        "  print(originalData[col]['notas'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1\n",
            "4645    100.5\n",
            "Name: notas, dtype: float64\n",
            "-1\n",
            "7952    100.5\n",
            "Name: notas, dtype: float64\n",
            "-1\n",
            "9687    98.0\n",
            "Name: notas, dtype: float64\n",
            "-1\n",
            "9121    98.5\n",
            "Name: notas, dtype: float64\n",
            "-1\n",
            "9020    100.5\n",
            "Name: notas, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}